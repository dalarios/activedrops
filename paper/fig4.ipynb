{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant libraries\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append('../py_files/')\n",
    "import quadrop2 as qd\n",
    "\n",
    "\n",
    "qd.set_plotting_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-procesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# base_dir = \"../../../Thomson Lab Dropbox/David Larios/activedrops/paper/paper-v2/fig3-assets/\"\n",
    "# qd.consolidate_images(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos0 does not exist. Skipping.\n",
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos1 does not exist. Skipping.\n",
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos2 does not exist. Skipping.\n",
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos3 does not exist. Skipping.\n",
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos4 does not exist. Skipping.\n",
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos5 does not exist. Skipping.\n",
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos6 does not exist. Skipping.\n",
      "Warning: ../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/Pos7 does not exist. Skipping.\n",
      "Conditions: ['BBB', 'BBO', 'BOB', 'BOO', 'OBB', 'OBO', 'OOB', 'OOO']\n",
      "Subconditions: ['Rep1']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "data_path =  \"../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/\"\n",
    "\n",
    "calibration_curve_paths = sorted(glob.glob(\"../../../Thomson Lab Dropbox/David Larios/activedrops/calibration_curve/***ugml.tif\"))\n",
    "\n",
    "\n",
    "conditions_dict = {\n",
    "    \"BBB\": \"Pos0\",\n",
    "    \"OBB\": \"Pos1\",\n",
    "    \"BOB\": \"Pos2\",\n",
    "    \"OOB\": \"Pos3\",\n",
    "    \"BBO\": \"Pos4\",\n",
    "    \"OBO\": \"Pos5\",\n",
    "    \"BOO\": \"Pos6\",\n",
    "    \"OOO\": \"Pos7\",\n",
    "}\n",
    "\n",
    "# # Organize PosX folders into condition folders\n",
    "qd.organize_conditions(data_path, conditions_dict)\n",
    "\n",
    "# # Now run the existing functions to reorganize the tiffs and rename the folders\n",
    "conditions, subconditions = qd.prepare_conditions(data_path)\\\n",
    "\n",
    "# conditions = ['K401_MTs', 'Kif3_MTs']\n",
    "\n",
    "time_interval_list = [60, 150, 75, 16, 40, 75, 150, 9]   # time intervals in seconds between frames for each condition\n",
    "\n",
    "print(\"Conditions:\", conditions)\n",
    "print(\"Subconditions:\", subconditions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd.reorgTiffsToOriginal(data_path, conditions, subconditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval_list = [60, 40, 75, 75, 150, 150, 16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing OOB - Rep1: 100%|██████████| 507/507 [02:26<00:00,  3.47it/s]\n",
      "Processing OOO - Rep1: 100%|██████████| 675/675 [03:11<00:00,  3.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "qd.fluorescence_heatmap(\n",
    "    data_path, \n",
    "    conditions[6:], \n",
    "    subconditions, \n",
    "    channel='cy5', \n",
    "    time_interval_list=[16, 9], \n",
    "    vmax=16, \n",
    "    skip_frames=2, \n",
    "    calibration_curve_paths=calibration_curve_paths, \n",
    "    show_scalebar=False,\n",
    "    # custom_title='K401 (slow-sustained)'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "qd.create_movies(\n",
    "    data_path, \n",
    "    conditions, \n",
    "    subconditions, \n",
    "    channel='cy5', \n",
    "    frame_rate=60,\n",
    "    skip_frames=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd.create_combined_heatmap_movie_custom_grid(\n",
    "    data_path, \n",
    "    conditions, \n",
    "    subconditions, \n",
    "    channel='cy5', \n",
    "    grid_rows=2, \n",
    "    grid_cols=4, \n",
    "    frame_rate=1,\n",
    "    batch_size=50\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def process_image(args):\n",
    "#     import matplotlib.patheffects as patheffects  # For scale bar text outline\n",
    "\n",
    "#     # Unpack arguments, allowing for an optional custom_title argument\n",
    "#     # If args has 14 elements, the last is custom_title; otherwise, custom_title is None/False\n",
    "#     if len(args) == 14:\n",
    "#         (image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition, custom_title) = args\n",
    "#     else:\n",
    "#         (image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition) = args\n",
    "#         custom_title = False\n",
    "\n",
    "#     # Read the image into a numpy array\n",
    "#     intensity_matrix = io.imread(image_file)\n",
    "\n",
    "#     if channel == \"cy5\":\n",
    "#         # Normalize intensity matrix to range [0, 1] for cy5 channel\n",
    "#         matrix_to_plot = intensity_matrix / 1000\n",
    "#         label = 'Normalized Fluorescence Intensity'\n",
    "#     else:\n",
    "#         # Convert intensity values to protein concentration using the calibration curve\n",
    "#         matrix_to_plot = calculate_protein_concentration_ug_ml(intensity_matrix, slope, intercept)\n",
    "#         matrix_to_plot = matrix_to_plot / 27000 * 1E6\n",
    "#         label = 'Protein concentration (nM)'\n",
    "\n",
    "#     # Plot the heatmap with a larger figure size\n",
    "#     fig, ax = plt.subplots(figsize=(16, 16))\n",
    "#     im = ax.imshow(matrix_to_plot, cmap='gray', interpolation='nearest', vmin=0, vmax=vmax)\n",
    "\n",
    "#     if show_scalebar:\n",
    "#         plt.colorbar(im, ax=ax, label=label)\n",
    "    \n",
    "#     # Remove axes and make image fill whole size\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.spines['bottom'].set_visible(False)\n",
    "#     ax.spines['left'].set_visible(False)\n",
    "    \n",
    "#     # Add title inside the image at top right, but ensure it doesn't go out of bounds\n",
    "#     if custom_title:\n",
    "#         title_text = str(custom_title)\n",
    "#     else:\n",
    "#         title_text = f\"{condition} \"\n",
    "\n",
    "#     # Truncate the title if it's too long to fit in the image\n",
    "#     # Estimate max characters based on font size and figure width\n",
    "#     # This is a heuristic: adjust max_chars as needed for your use case\n",
    "#     max_chars = 30  # Reduced for right alignment\n",
    "#     if len(title_text) > max_chars:\n",
    "#         title_text = title_text[:max_chars-3] + \"...\"\n",
    "\n",
    "#     # --- Custom coloring for all 'O' (orange) and all 'B' (blue) in the title ---\n",
    "#     def draw_colored_title_all(ax, text, x, y, fontsize=80):\n",
    "#         import matplotlib.patheffects as patheffects\n",
    "#         # Colors\n",
    "#         default_color = 'white'\n",
    "#         o_color = '#FFA500'  # orange\n",
    "#         b_color = '#1E90FF'  # blue\n",
    "\n",
    "#         # Split text into segments by character, assigning color\n",
    "#         segments = []\n",
    "#         for c in text:\n",
    "#             if c.upper() == 'O':\n",
    "#                 segments.append((c, o_color))\n",
    "#             elif c.upper() == 'B':\n",
    "#                 segments.append((c, b_color))\n",
    "#             else:\n",
    "#                 segments.append((c, default_color))\n",
    "\n",
    "#         # Now, draw each segment with correct color, right-aligned\n",
    "#         # We'll use a dummy text to get the total width, then draw each segment offset from the right\n",
    "#         import matplotlib.transforms as mtransforms\n",
    "#         renderer = fig.canvas.get_renderer()\n",
    "#         # Compose the full text for width calculation\n",
    "#         full_text = ''.join(seg[0] for seg in segments)\n",
    "#         # Get the right-aligned anchor in axes coordinates\n",
    "#         right_x_axes = x\n",
    "#         y_axes = y\n",
    "#         # Convert axes coords to display coords\n",
    "#         right_disp, y_disp = ax.transAxes.transform((right_x_axes, y_axes))\n",
    "#         # Now, measure the width of the full text in display coords\n",
    "#         t = ax.text(0, 0, full_text, fontsize=fontsize, weight='bold', va='top', ha='left',\n",
    "#                     path_effects=[patheffects.withStroke(linewidth=3, foreground='black', alpha=0.7)],\n",
    "#                     color=default_color)\n",
    "#         fig.canvas.draw()  # Needed to get correct bbox\n",
    "#         bbox = t.get_window_extent(renderer=renderer)\n",
    "#         total_width = bbox.width\n",
    "#         t.remove()\n",
    "#         # Now, draw each segment, right-aligned\n",
    "#         offset = 0\n",
    "#         for seg, color in reversed(segments):\n",
    "#             # Measure width of this segment\n",
    "#             t = ax.text(0, 0, seg, fontsize=fontsize, weight='bold', va='top', ha='left',\n",
    "#                         path_effects=[patheffects.withStroke(linewidth=3, foreground='black', alpha=0.7)],\n",
    "#                         color=color)\n",
    "#             fig.canvas.draw()\n",
    "#             bbox = t.get_window_extent(renderer=renderer)\n",
    "#             seg_width = bbox.width\n",
    "#             t.remove()\n",
    "#             # Place this segment at (right_disp - offset - seg_width, y_disp)\n",
    "#             # Convert back to axes coords\n",
    "#             x_disp = right_disp - offset - seg_width\n",
    "#             x_axes, _ = ax.transAxes.inverted().transform((x_disp, y_disp))\n",
    "#             ax.text(x_axes, y_axes, seg, \n",
    "#                     transform=ax.transAxes, color=color, fontsize=fontsize, \n",
    "#                     weight='bold', va='top', ha='left',\n",
    "#                     path_effects=[patheffects.withStroke(linewidth=3, foreground='black', alpha=0.7)],\n",
    "#                     clip_on=True)\n",
    "#             offset += seg_width\n",
    "\n",
    "#     # Use the custom colored title function with larger font size\n",
    "#     draw_colored_title_all(ax, title_text, 0.98, 0.98, fontsize=100)\n",
    "    \n",
    "#     # Add timer information at top left in white\n",
    "#     time_hours = (i - min_frame) * time_interval * skip_frames / 3600\n",
    "#     time_minutes = (i - min_frame) * time_interval * skip_frames / 60\n",
    "    \n",
    "#     ax.text(0.02, 0.99, f\"{time_hours:.2f} h\", \n",
    "#             transform=ax.transAxes, color='white', fontsize=38, \n",
    "#             weight='bold', va='top', ha='left',\n",
    "#             path_effects=[patheffects.withStroke(linewidth=3, foreground='black', alpha=0.7)])\n",
    "    \n",
    "#     ax.text(0.02, 0.94, f\"{time_minutes:.2f} min\", \n",
    "#             transform=ax.transAxes, color='white', fontsize=38, \n",
    "#             weight='bold', va='top', ha='left',\n",
    "#             path_effects=[patheffects.withStroke(linewidth=3, foreground='black', alpha=0.7)])\n",
    "\n",
    "#     # Draw a 1mm scale bar (730 pixels) at the bottom right\n",
    "#     scalebar_length_px = 730\n",
    "#     scalebar_height = max(4, int(matrix_to_plot.shape[0] * 0.005))  # 4 pixels or 0.5% of image height\n",
    "#     color = 'white' if np.mean(matrix_to_plot) < 0.5 * vmax else 'black'\n",
    "\n",
    "#     # Coordinates for the scale bar\n",
    "#     x_start = matrix_to_plot.shape[1] - scalebar_length_px - 40  # 40 px from right edge\n",
    "#     x_end = matrix_to_plot.shape[1] - 40\n",
    "#     y_pos = matrix_to_plot.shape[0] - 40  # 40 px from bottom\n",
    "\n",
    "#     # Draw the scale bar as a thick line\n",
    "#     ax.hlines(\n",
    "#         y=y_pos, xmin=x_start, xmax=x_end, colors=color, linewidth=scalebar_height, zorder=10, alpha=0.9\n",
    "#     )\n",
    "#     # Add text label above the scale bar\n",
    "#     ax.text(\n",
    "#         (x_start + x_end) / 2, y_pos - 15, \"1 mm\", color=color, fontsize=18, ha='center', va='bottom', weight='bold', zorder=11,\n",
    "#         path_effects=[patheffects.withStroke(linewidth=3, foreground='black' if color == 'white' else 'white', alpha=0.7)]\n",
    "#     )\n",
    "\n",
    "#     # Save the heatmap with no borders\n",
    "#     heatmap_filename = f\"heatmap_frame_{i}.png\"\n",
    "#     heatmap_path = os.path.join(output_directory_path, heatmap_filename)\n",
    "#     plt.savefig(heatmap_path, bbox_inches='tight', pad_inches=0, dpi=200)\n",
    "#     plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name, including time_multiplier and fps_output.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    # Format time_multiplier and fps_output for filename (avoid decimal point if possible)\n",
    "    tm_str = f\"{int(time_multiplier)}\" if int(time_multiplier) == time_multiplier else f\"{time_multiplier}\"\n",
    "    fps_str = f\"{int(fps_output)}\" if int(fps_output) == fps_output else f\"{fps_output}\"\n",
    "    final_output_file = os.path.join(\n",
    "        out_dir, \n",
    "        f\"{proteins_combined}_{channel}_synced_tm{tm_str}_fps{fps_str}.avi\"\n",
    "    )\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie duration: {playback_duration_sec:.2f} seconds\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved to: {final_output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 16*2,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 9*2,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 1  # Maximum temporal resolution!\n",
    "grid_shape = (1, 2)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=90, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
