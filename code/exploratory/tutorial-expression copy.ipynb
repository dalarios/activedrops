{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# utilities\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "import cv2\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def reorgTiffsToOriginal(data_path, conditions, subconditions):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_path (str): Path to the data directory.\n",
    "        conditions (list): List of conditions.\n",
    "        subconditions (list): List of subconditions.\n",
    "        \n",
    "    This function renames the subconditions as PosX and moves the raw data to the \"original\" folder.\n",
    "    \"\"\"\n",
    "    for condition in conditions:\n",
    "        # Get the actual subconditions in the directory\n",
    "        actual_subconditions = [name for name in os.listdir(os.path.join(data_path, condition)) if os.path.isdir(os.path.join(data_path, condition, name))]\n",
    "        \n",
    "        # Rename the actual subconditions to match the subconditions in your list\n",
    "        for i, actual_subcondition in enumerate(sorted(actual_subconditions)):\n",
    "            os.rename(os.path.join(data_path, condition, actual_subcondition), os.path.join(data_path, condition, subconditions[i]))\n",
    "        \n",
    "        for subcondition in subconditions:\n",
    "            # Construct the path to the subcondition directory\n",
    "            subcondition_path = os.path.join(data_path, condition, subcondition)\n",
    "            \n",
    "            # Create the path for the \"original\" directory within the subcondition directory\n",
    "            original_dir_path = os.path.join(subcondition_path, \"original\")\n",
    "            \n",
    "            # Always create the \"original\" directory\n",
    "            os.makedirs(original_dir_path, exist_ok=True)\n",
    "            \n",
    "            # Iterate over all files in the subcondition directory\n",
    "            for filename in os.listdir(subcondition_path):\n",
    "                # Check if the file is a .tif file\n",
    "                if filename.endswith(\".tif\"):\n",
    "                    # Construct the full path to the file\n",
    "                    file_path = os.path.join(subcondition_path, filename)\n",
    "                    \n",
    "                    # Construct the path to move the file to\n",
    "                    destination_path = os.path.join(original_dir_path, filename)\n",
    "                    \n",
    "                    # Move the file to the \"original\" directory\n",
    "                    shutil.move(file_path, destination_path)\n",
    "            print(f\"Moved .tif files from {subcondition_path} to {original_dir_path}\")\n",
    "\n",
    "\n",
    "def ensure_output_dir(output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "def calculate_mean_intensity(path):\n",
    "    \"\"\"Calculate mean intensity of an image.\"\"\"\n",
    "    return io.imread(path).mean()\n",
    "\n",
    "\n",
    "def calculate_protein_concentration(mean_intensity, intercept, slope):\n",
    "    \"\"\"Calculate protein concentration in ng/ul and nM.\"\"\"\n",
    "    conc_ng_ul = (mean_intensity - intercept) / slope\n",
    "    return conc_ng_ul\n",
    "\n",
    "\n",
    "def calculate_protein_concentration_nM(conc_ng_ul, mw_kda):\n",
    "    \"\"\"Convert protein concentration from ng/ul to nM.\"\"\"\n",
    "    conc_nM = (conc_ng_ul * 1e-3) / (mw_kda * 1e3) * 1e9\n",
    "    return conc_nM\n",
    "\n",
    "\n",
    "def calculate_number_of_protein_molecules(protein_mass, mw_kda):\n",
    "    \"\"\"Calculate number of protein molecules.\"\"\"\n",
    "    return (protein_mass * 6e14) / (mw_kda * 1e3)\n",
    "\n",
    "\n",
    "def convert_time_units(time_values_s):\n",
    "    \"\"\"Convert time values from seconds to minutes and hours.\"\"\"\n",
    "    time_values_min = time_values_s / 60\n",
    "    time_values_h = time_values_s / 3600\n",
    "    return time_values_s, time_values_min, time_values_h\n",
    "\n",
    "\n",
    "def process_image(args):\n",
    "    image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition = args\n",
    "    # Read the image into a numpy array\n",
    "    intensity_matrix = io.imread(image_file)\n",
    "\n",
    "    if channel == \"Cy5\":\n",
    "        matrix_to_plot = intensity_matrix\n",
    "        # Use raw intensity for cy5 channel\n",
    "        label = 'Fluorescence Intensity'\n",
    "    else:\n",
    "        # Convert intensity values to protein concentration using the calibration curve\n",
    "        matrix_to_plot = calculate_protein_concentration(intensity_matrix, slope, intercept)\n",
    "        matrix_to_plot = matrix_to_plot / 27000 * 1E6\n",
    "        label = 'Protein concentration (nM)'\n",
    "\n",
    "    # Plot the heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    im = ax.imshow(matrix_to_plot, cmap='gray', interpolation='nearest', vmin=0, vmax=vmax)\n",
    "\n",
    "    if show_scalebar:\n",
    "        plt.colorbar(im, ax=ax, label=label)\n",
    "    plt.title(f\"Time (min): {(i - min_frame) * time_interval * skip_frames / 60:.2f} \\nTime (h): {(i - min_frame) * time_interval * skip_frames / 3600:.2f} \\n{condition} - {subcondition} - {channel}\", fontsize=20)\n",
    "    plt.xlabel('x [µm]')\n",
    "    plt.ylabel('y [µm]')\n",
    "    plt.grid(True, color='#d3d3d3', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # Save the heatmap\n",
    "    heatmap_filename = f\"heatmap_frame_{i}.png\"\n",
    "    heatmap_path = os.path.join(output_directory_path, heatmap_filename)\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def fluorescence_heatmap(data_path, conditions, subconditions, channel, time_interval_list, min_frame, max_frame, vmax, skip_frames=1, calibration_curve_paths=None, show_scalebar=True):\n",
    "    \"\"\"\n",
    "    Reads each image as a matrix, creates, and saves a heatmap representing the normalized pixel-wise fluorescence intensity.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base directory where the images are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): Channel specifying the fluorescence ('cy5' or 'gfp').\n",
    "    - time_interval_list (list): List of time intervals in seconds between frames for each condition.\n",
    "    - min_frame (int): Minimum frame number to start processing from.\n",
    "    - max_frame (int): Maximum frame number to stop processing at.\n",
    "    - vmax (float): Maximum value for color scale in the heatmap.\n",
    "    - skip_frames (int): Interval to skip frames (default is 1, meaning process every frame).\n",
    "    - calibration_curve_paths (list): List of file paths for the calibration curve images.\n",
    "    - show_scalebar (bool): Whether to show the color scale bar in the heatmap.\n",
    "    \"\"\"\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\", \"movies\")\n",
    "    ensure_output_dir(output_data_dir)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        time_interval = time_interval_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            # Determine the directory paths based on the channel\n",
    "            input_directory_path = os.path.join(data_path, condition, subcondition, \"original\")\n",
    "            output_directory_path = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "\n",
    "            # Create the output directory if it doesn't exist, or clear it if it does\n",
    "            if os.path.exists(output_directory_path):\n",
    "                shutil.rmtree(output_directory_path)\n",
    "            os.makedirs(output_directory_path, exist_ok=True)\n",
    "\n",
    "            # Get all .tif files in the folder\n",
    "            image_files = sorted(glob.glob(os.path.join(input_directory_path, f\"*{channel}*.tif\")))[min_frame:max_frame:skip_frames]\n",
    "\n",
    "            # Setup calibration curve for non-cy5 channels\n",
    "            slope, intercept = None, None\n",
    "            if channel != \"Cy5\":\n",
    "                # Calibration curve data and fit\n",
    "                sample_concentration_values = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "\n",
    "                if calibration_curve_paths is None or len(calibration_curve_paths) != len(sample_concentration_values):\n",
    "                    raise ValueError(f\"Mismatch in lengths: {len(calibration_curve_paths)} calibration images, {len(sample_concentration_values)} sample concentrations\")\n",
    "\n",
    "                with mp.Pool(mp.cpu_count()) as pool:\n",
    "                    mean_intensity_calibration = pool.map(calculate_mean_intensity, calibration_curve_paths)\n",
    "                slope, intercept = np.polyfit(sample_concentration_values, mean_intensity_calibration, 1)\n",
    "\n",
    "            # Prepare arguments for multiprocessing\n",
    "            args = [(image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition) for i, image_file in enumerate(image_files, start=min_frame)]\n",
    "\n",
    "            # Use multiprocessing to process images\n",
    "            with mp.Pool(mp.cpu_count()) as pool:\n",
    "                list(tqdm(pool.imap(process_image, args), total=len(args), desc=f\"Processing {condition} - {subcondition}\"))\n",
    "\n",
    "\n",
    "def prepare_conditions(data_path, num_reps):\n",
    "    # List conditions while ignoring 'output_data'\n",
    "    conditions = natsorted([\n",
    "        f for f in os.listdir(data_path) \n",
    "        if os.path.isdir(os.path.join(data_path, f)) and f != 'output_data'\n",
    "    ])\n",
    "    \n",
    "    # Generate subconditions list based on num_reps\n",
    "    subconditions = [f\"Rep{x}\" for x in range(1, num_reps + 1)]\n",
    "    \n",
    "    return conditions, subconditions\n",
    "\n",
    "\n",
    "def process_video_creation(args):\n",
    "    condition, subcondition, images_dir, out_path, frame_rate, max_frame = args\n",
    "\n",
    "    image_files = natsorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found for subcondition {subcondition}.\")\n",
    "        return\n",
    "\n",
    "    # Limit the number of files if max_frame is specified\n",
    "    image_files = image_files[:max_frame] if max_frame is not None else image_files\n",
    "\n",
    "    # Get the resolution of the first image (assuming all images are the same size)\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    video_resolution = (first_image.shape[1], first_image.shape[0])  # Width x Height\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, frame_rate, video_resolution)\n",
    "\n",
    "    for file in tqdm(image_files, desc=f\"Creating video for {condition}\", leave=False):\n",
    "        img = cv2.imread(file)\n",
    "        out.write(img)  # Write the image as a frame in the video\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video saved to {out_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def ensure_output_dir(output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "def process_video_creation(args):\n",
    "    condition, subcondition, images_dir, out_path, frame_rate, max_frame = args\n",
    "\n",
    "    image_files = natsorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found for subcondition {subcondition}.\")\n",
    "        return\n",
    "\n",
    "    # Limit the number of files if max_frame is specified\n",
    "    image_files = image_files[:max_frame] if max_frame is not None else image_files\n",
    "\n",
    "    # Get the resolution of the first image (assuming all images are the same size)\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    video_resolution = (first_image.shape[1], first_image.shape[0])  # Width x Height\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, frame_rate, video_resolution)\n",
    "\n",
    "    for file in tqdm(image_files, desc=f\"Creating video for {condition} - {subcondition}\", leave=False):\n",
    "        img = cv2.imread(file)\n",
    "        out.write(img)  # Write the image as a frame in the video\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video saved to {out_path}\")\n",
    "\n",
    "def create_movies(data_path, conditions, subconditions, channel, frame_rate=30, max_frame=None, delete_temp_dirs=False):\n",
    "    \"\"\"\n",
    "    Creates video files from heatmaps stored in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base path where the heatmaps are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): The specific channel being processed ('cy5' or 'gfp').\n",
    "    - frame_rate (int): Frame rate for the output video. Defaults to 30.\n",
    "    - max_frame (int, optional): Maximum number of frames to be included in the video. If None, all frames are included.\n",
    "    - delete_temp_dirs (bool): If True, deletes temporary heatmap directories after movie creation.\n",
    "    \"\"\"\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\", \"movies\")\n",
    "    ensure_output_dir(output_data_dir)\n",
    "\n",
    "    args_list = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        for subcondition in subconditions:\n",
    "            images_dir = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "            video_filename = f\"{condition}_{subcondition}_{channel}.avi\"\n",
    "            out_path = os.path.join(output_data_dir, video_filename)\n",
    "\n",
    "            # Prepare arguments for multiprocessing\n",
    "            args_list.append((condition, subcondition, images_dir, out_path, frame_rate, max_frame))\n",
    "\n",
    "    # Use multiprocessing to process video creation for all conditions and subconditions\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        list(tqdm(pool.imap(process_video_creation, args_list), total=len(args_list), desc=\"Creating videos\"))\n",
    "\n",
    "    # Delete temporary directories if specified\n",
    "    if delete_temp_dirs:\n",
    "        for condition in conditions:\n",
    "            for subcondition in subconditions:\n",
    "                temp_dir = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "                if os.path.exists(temp_dir):\n",
    "                    shutil.rmtree(temp_dir)\n",
    "                    print(f\"Deleted temporary directory: {temp_dir}\")\n",
    "\n",
    "\n",
    "def quantify_tiffiles(data_path, conditions, subconditions, calibration_curve_paths, mw_kda_list, droplet_volume_list, time_interval_s_list):\n",
    "    \"\"\"Process images to calculate protein concentration and generate plots.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Sort the calibration curve paths\n",
    "    calibration_curve_paths = sorted(calibration_curve_paths)\n",
    "\n",
    "    # Calibration curve data and fit\n",
    "    sample_concentration_values = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        mean_intensity_calibration = pool.map(calculate_mean_intensity, calibration_curve_paths)\n",
    "    slope, intercept = np.polyfit(sample_concentration_values, mean_intensity_calibration, 1)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        # Get condition-specific parameters\n",
    "        mw_kda = mw_kda_list[idx]\n",
    "        droplet_volume = droplet_volume_list[idx]\n",
    "        time_interval_s = time_interval_s_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            # Construct paths based on condition and subcondition\n",
    "            pattern = os.path.join(data_path, condition, subcondition, \"original\", \"img_*********_4x_GFP_000.tif\")\n",
    "            paths = sorted(glob.glob(pattern))\n",
    "\n",
    "            if not paths:\n",
    "                print(f\"No image files found for condition {condition}, subcondition {subcondition}.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate mean intensity for samples\n",
    "            with mp.Pool(mp.cpu_count()) as pool:\n",
    "                mean_intensity_list = list(tqdm(pool.imap(calculate_mean_intensity, paths), total=len(paths), desc=f\"Calculating intensities for {condition} - {subcondition}\"))\n",
    "\n",
    "            # Calculate protein concentrations in ng/ul\n",
    "            protein_concentration_list = [calculate_protein_concentration(intensity, intercept, slope) for intensity in mean_intensity_list]\n",
    "\n",
    "            # Convert to nM\n",
    "            protein_concentration_nM_list = [calculate_protein_concentration_nM(conc_ng_ul, mw_kda) for conc_ng_ul in protein_concentration_list]\n",
    "\n",
    "            # Normalize intensities and concentrations\n",
    "            min_intensity = min(mean_intensity_list)\n",
    "            mean_intensity_list = np.array(mean_intensity_list) - min_intensity\n",
    "            protein_concentration_list = np.array(protein_concentration_list) - min(protein_concentration_list)\n",
    "            protein_concentration_nM_list = np.array(protein_concentration_nM_list) - min(protein_concentration_nM_list)\n",
    "\n",
    "            # Time values\n",
    "            time_values_s = np.arange(len(mean_intensity_list)) * time_interval_s\n",
    "            time_values_s, time_values_min, time_values_h = convert_time_units(time_values_s)\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                \"Condition\": condition,\n",
    "                \"Subcondition\": subcondition,\n",
    "                \"Time_s\": time_values_s,\n",
    "                \"Time_min\": time_values_min,\n",
    "                \"Time_h\": time_values_h,\n",
    "                \"Mean Intensity\": mean_intensity_list,\n",
    "                \"Protein Concentration_ng_ul\": protein_concentration_list,\n",
    "                \"Protein Concentration_nM\": protein_concentration_nM_list\n",
    "            })\n",
    "\n",
    "            # Calculate number of protein molecules\n",
    "            protein_mass_list = df[\"Protein Concentration_ng_ul\"] * droplet_volume\n",
    "            df[\"Number of Protein Molecules\"] = [calculate_number_of_protein_molecules(mass, mw_kda) for mass in protein_mass_list]\n",
    "\n",
    "            # Calculate rate of change of protein molecules\n",
    "            t_vals = np.linspace(0, (len(df) - 1) * time_interval_s, len(df))\n",
    "            dp_dt = gaussian_filter1d(np.gradient(df[\"Number of Protein Molecules\"], t_vals), sigma=2)\n",
    "            df[\"Rate of Change of Number of Protein Molecules (PM/s)\"] = dp_dt\n",
    "\n",
    "            # Append the data for this condition and subcondition to the list\n",
    "            all_data.append(df)\n",
    "\n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Calculate mean for each condition across subconditions\n",
    "    mean_df = combined_df.groupby([\"Condition\", \"Time_s\", \"Time_min\", \"Time_h\"]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "    # Set the output directory within the data path\n",
    "    output_dir = os.path.join(data_path, \"output_data\")\n",
    "    ensure_output_dir(output_dir)\n",
    "\n",
    "    # Save combined results to CSV\n",
    "    combined_csv_path = os.path.join(output_dir, \"combined_experiment.csv\")\n",
    "    combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "    # Save mean results to CSV\n",
    "    mean_csv_path = os.path.join(output_dir, \"mean_experiment.csv\")\n",
    "    mean_df.to_csv(mean_csv_path, index=False)\n",
    "\n",
    "    # Plotting\n",
    "    plot_results(combined_df, mean_df, output_dir, sample_concentration_values, mean_intensity_calibration, slope, intercept)\n",
    "\n",
    "    return combined_csv_path, mean_csv_path\n",
    "\n",
    "\n",
    "def plot_results(df, mean_df, output_dir, sample_concentration_values, mean_intensity_calibration, slope, intercept):\n",
    "    \"\"\"Generate plots based on the processed data.\"\"\"\n",
    "    # Create subdirectories for plots\n",
    "    single_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"single_plots\")\n",
    "    combined_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"combined_plots\")\n",
    "    mean_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"mean_plots\")\n",
    "    ensure_output_dir(single_plot_dir)\n",
    "    ensure_output_dir(combined_plot_dir)\n",
    "    ensure_output_dir(mean_plot_dir)\n",
    "\n",
    "    # Plot calibration curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sample_concentration_values, mean_intensity_calibration, 'o', label='Data points', linewidth=0.75, markersize=5)\n",
    "    plt.plot(sample_concentration_values, slope * np.array(sample_concentration_values) + intercept, 'r-', label=f'Fit: y = {slope:.2f}x + {intercept:.2f}', linewidth=0.75)\n",
    "    plt.title('Mean Intensity vs Protein Concentration')\n",
    "    plt.xlabel('Protein Concentration (ug/ml)')\n",
    "    plt.ylabel('Mean Intensity')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(single_plot_dir, 'mean_intensity_vs_protein_concentration.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot calibration curve (log scale)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sample_concentration_values, mean_intensity_calibration, 'o', label='Data points', linewidth=0.75, markersize=5)\n",
    "    plt.plot(sample_concentration_values, slope * np.array(sample_concentration_values) + intercept, 'r-', label=f'Fit: y = {slope:.2f}x + {intercept:.2f}', linewidth=0.75)\n",
    "    plt.title('Mean Intensity vs Protein Concentration (Log Scale)')\n",
    "    plt.xlabel('Protein Concentration (ug/ml)')\n",
    "    plt.ylabel('Mean Intensity')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(single_plot_dir, 'mean_intensity_vs_protein_concentration_log.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Time units and concentration units to plot\n",
    "    time_units = [(\"Time_s\", \"Time_s\"), (\"Time_min\", \"Time_min\"), (\"Time_h\", \"Time_h\")]\n",
    "    protein_concentration_units = [\n",
    "        (\"Protein Concentration_ng_ul\", \"Protein Concentration_ng_ul\"),\n",
    "        (\"Protein Concentration_nM\", \"Protein Concentration_nM\"),\n",
    "        (\"Number of Protein Molecules\", \"Number of Protein Molecules\")\n",
    "    ]\n",
    "\n",
    "    # Plot protein concentration over time for each time and concentration unit\n",
    "    for time_unit, time_label in time_units:\n",
    "        for conc_unit, conc_label in protein_concentration_units:\n",
    "            # Individual plots for each condition and subcondition\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                # Create a directory for each condition's single plots\n",
    "                condition_single_plot_dir = os.path.join(single_plot_dir, f\"{condition}_single_plots\")\n",
    "                ensure_output_dir(condition_single_plot_dir)\n",
    "\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "                    plt.title(f'{conc_label} vs {time_label} for {condition} {subcondition}')\n",
    "                    plt.xlabel(time_label)\n",
    "                    plt.ylabel(conc_label)\n",
    "                    plt.legend()\n",
    "                    plt.grid(True)\n",
    "                    plt.savefig(os.path.join(condition_single_plot_dir, f'{condition}_{subcondition}_{conc_label}_vs_{time_label}.png'))\n",
    "                    plt.close()\n",
    "\n",
    "            # Combined plots for all conditions and subconditions\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Combined {conc_label} vs {time_label} for all conditions')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(combined_plot_dir, f'combined_{conc_label}_vs_{time_label}.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Combined plots for all conditions and subconditions (log scale)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Combined {conc_label} vs {time_label} for all conditions (Log Scale)')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(combined_plot_dir, f'combined_{conc_label}_vs_{time_label}_log.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Mean plots for each condition\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in mean_df[\"Condition\"].unique():\n",
    "                condition_mean_data = mean_df[mean_df[\"Condition\"] == condition]\n",
    "                plt.plot(condition_mean_data[time_unit], condition_mean_data[conc_unit], 'o-', label=f'{condition} Mean', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Mean {conc_label} vs {time_label} for each condition')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(mean_plot_dir, f'mean_{conc_label}_vs_{time_label}.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Mean plots for each condition (log scale)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in mean_df[\"Condition\"].unique():\n",
    "                condition_mean_data = mean_df[mean_df[\"Condition\"] == condition]\n",
    "                plt.plot(condition_mean_data[time_unit], condition_mean_data[conc_unit], 'o-', label=f'{condition} Mean', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Mean {conc_label} vs {time_label} for each condition (Log Scale)')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(mean_plot_dir, f'mean_{conc_label}_vs_{time_label}_log.png'))\n",
    "            plt.close()\n",
    "\n",
    "    # Plot rate of change of protein molecules\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for condition in df[\"Condition\"].unique():\n",
    "        for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "            condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "            plt.plot(condition_data[\"Time_h\"], condition_data[\"Rate of Change of Number of Protein Molecules (PM/s)\"], 'o', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "    plt.title('Rate of Change of Number of Protein Molecules vs Time_h')\n",
    "    plt.xlabel('Time_h')\n",
    "    plt.ylabel('Rate of Change (PM/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(combined_plot_dir, 'rate_of_change_of_protein_molecules_vs_time_h.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot rate of change of protein molecules (log scale)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for condition in df[\"Condition\"].unique():\n",
    "        for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "            condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "            plt.plot(condition_data[\"Time_h\"], condition_data[\"Rate of Change of Number of Protein Molecules (PM/s)\"], 'o', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "    plt.title('Rate of Change of Number of Protein Molecules vs Time_h (Log Scale)')\n",
    "    plt.xlabel('Time_h')\n",
    "    plt.ylabel('Rate of Change (PM/s)')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(combined_plot_dir, 'rate_of_change_of_protein_molecules_vs_time_h_log.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_combined_heatmap_movie_custom_grid(data_path, conditions, subconditions, channel, grid_rows=None, grid_cols=None, frame_rate=30, delete_temp_dirs=False):\n",
    "    \"\"\"\n",
    "    Combines heatmaps from different conditions and subconditions into a single video.\n",
    "    Allows specifying the number of grid rows and columns or uses an adaptive layout based on subconditions.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base path where the heatmaps are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): The specific channel being processed ('cy5' or 'gfp').\n",
    "    - grid_rows (int, optional): Number of rows in the grid. If None, calculated adaptively.\n",
    "    - grid_cols (int, optional): Number of columns in the grid. If None, calculated adaptively.\n",
    "    - frame_rate (int): Frame rate for the output video. Defaults to 30.\n",
    "    - delete_temp_dirs (bool): If True, deletes temporary heatmap directories after movie creation.\n",
    "    \"\"\"\n",
    "    # Determine grid dimensions if not provided\n",
    "    total_plots = len(conditions) * len(subconditions)\n",
    "    \n",
    "    if grid_rows is None or grid_cols is None:\n",
    "        if len(subconditions) == 1:\n",
    "            # Use a rectangular grid with more columns than rows when only one subcondition\n",
    "            grid_cols = int(np.ceil(np.sqrt(total_plots)))\n",
    "            grid_rows = int(np.ceil(total_plots / grid_cols))\n",
    "            \n",
    "            # Adjust columns and rows to minimize blank spaces\n",
    "            while grid_cols * grid_rows >= total_plots:\n",
    "                if (grid_cols - 1) * grid_rows >= total_plots:\n",
    "                    grid_cols -= 1\n",
    "                elif grid_cols * (grid_rows - 1) >= total_plots:\n",
    "                    grid_rows -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            # Use a column-row layout with conditions in columns and subconditions in rows\n",
    "            grid_rows = len(subconditions)\n",
    "            grid_cols = len(conditions)\n",
    "    \n",
    "    # Define the output directory for temporary images\n",
    "    temp_img_dir = os.path.join(data_path, \"output_data\", \"temp_images\")\n",
    "    ensure_output_dir(temp_img_dir)\n",
    "\n",
    "    # Determine the number of frames based on the first condition and subcondition\n",
    "    sample_image_dir = os.path.join(data_path, \"output_data\", \"movies\", f\"{conditions[0]}_{subconditions[0]}_heatmaps_{channel}\")\n",
    "    sample_image_files = natsorted(glob.glob(os.path.join(sample_image_dir, \"*.png\")))\n",
    "    num_frames = len(sample_image_files)\n",
    "\n",
    "    if num_frames == 0:\n",
    "        print(f\"No frames to process. Check if the directories exist and contain images.\")\n",
    "        return\n",
    "\n",
    "    # Loop through each frame\n",
    "    for frame_index in tqdm(range(num_frames), desc=\"Creating combined frames\"):\n",
    "        fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols * 6, grid_rows * 6))\n",
    "        plt.subplots_adjust(hspace=0.1, wspace=0.1)  # Adjust spacing\n",
    "\n",
    "        # Ensure axes is always 2D\n",
    "        if grid_rows == 1 and grid_cols == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif grid_rows == 1 or grid_cols == 1:\n",
    "            axes = np.array(axes).reshape(grid_rows, grid_cols)\n",
    "\n",
    "        plot_index = 0\n",
    "\n",
    "        # Loop through each condition and subcondition\n",
    "        for col_idx, condition in enumerate(conditions):\n",
    "            for row_idx, subcondition in enumerate(subconditions):\n",
    "                # Determine the image path\n",
    "                images_dir = os.path.join(data_path, \"output_data\", \"movies\", f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "                image_files = natsorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "                if frame_index < len(image_files):\n",
    "                    image_path = image_files[frame_index]\n",
    "                    img = io.imread(image_path)\n",
    "\n",
    "                    # Plot the image in the appropriate subplot\n",
    "                    ax = axes[row_idx if len(subconditions) > 1 else plot_index // grid_cols,\n",
    "                              col_idx if len(subconditions) > 1 else plot_index % grid_cols]\n",
    "                    ax.imshow(img, cmap='gray', vmin=0, vmax=img.max())\n",
    "                    ax.axis('off')  # Remove axes\n",
    "\n",
    "                    plot_index += 1\n",
    "\n",
    "        # Turn off any unused subplots\n",
    "        for ax in axes.flatten()[plot_index:]:\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Save the combined frame\n",
    "        combined_image_path = os.path.join(temp_img_dir, f\"combined_frame_{frame_index:04d}.png\")\n",
    "        plt.savefig(combined_image_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Compile the images into a video using OpenCV\n",
    "    combined_image_files = natsorted(glob.glob(os.path.join(temp_img_dir, \"combined_frame_*.png\")))\n",
    "\n",
    "    # Get the resolution of the first image\n",
    "    first_image = cv2.imread(combined_image_files[0])\n",
    "    height, width, layers = first_image.shape\n",
    "    video_resolution = (width, height)\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\")\n",
    "    output_filename = f\"combined_heatmap_movie_{channel}.avi\"\n",
    "    output_file = os.path.join(output_data_dir, output_filename)\n",
    "    ensure_output_dir(output_data_dir)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, frame_rate, video_resolution)\n",
    "\n",
    "    for image_file in combined_image_files:\n",
    "        img = cv2.imread(image_file)\n",
    "        out.write(img)  # Write the image as a frame in the video\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Combined video saved to {output_file}\")\n",
    "\n",
    "    # Clean up temporary images\n",
    "    shutil.rmtree(temp_img_dir)\n",
    "\n",
    "    # Delete temporary directories if specified\n",
    "    if delete_temp_dirs:\n",
    "        for condition in conditions:\n",
    "            for subcondition in subconditions:\n",
    "                temp_dir = os.path.join(data_path, \"output_data\", \"movies\", f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "                if os.path.exists(temp_dir):\n",
    "                    shutil.rmtree(temp_dir)\n",
    "                    print(f\"Deleted temporary directory: {temp_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# utilities\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)\n",
    "from tqdm import tqdm\n",
    "from natsort import natsorted\n",
    "import cv2\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def reorgTiffsToOriginal(data_path, conditions, subconditions):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_path (str): Path to the data directory.\n",
    "        conditions (list): List of conditions.\n",
    "        subconditions (list): List of subconditions.\n",
    "        \n",
    "    This function renames the subconditions as PosX and moves the raw data to the \"original\" folder.\n",
    "    \"\"\"\n",
    "    for condition in conditions:\n",
    "        # Get the actual subconditions in the directory\n",
    "        actual_subconditions = [name for name in os.listdir(os.path.join(data_path, condition)) if os.path.isdir(os.path.join(data_path, condition, name))]\n",
    "        \n",
    "        # Rename the actual subconditions to match the subconditions in your list\n",
    "        for i, actual_subcondition in enumerate(sorted(actual_subconditions)):\n",
    "            os.rename(os.path.join(data_path, condition, actual_subcondition), os.path.join(data_path, condition, subconditions[i]))\n",
    "        \n",
    "        for subcondition in subconditions:\n",
    "            # Construct the path to the subcondition directory\n",
    "            subcondition_path = os.path.join(data_path, condition, subcondition)\n",
    "            \n",
    "            # Create the path for the \"original\" directory within the subcondition directory\n",
    "            original_dir_path = os.path.join(subcondition_path, \"original\")\n",
    "            \n",
    "            # Always create the \"original\" directory\n",
    "            os.makedirs(original_dir_path, exist_ok=True)\n",
    "            \n",
    "            # Iterate over all files in the subcondition directory\n",
    "            for filename in os.listdir(subcondition_path):\n",
    "                # Check if the file is a .tif file\n",
    "                if filename.endswith(\".tif\"):\n",
    "                    # Construct the full path to the file\n",
    "                    file_path = os.path.join(subcondition_path, filename)\n",
    "                    \n",
    "                    # Construct the path to move the file to\n",
    "                    destination_path = os.path.join(original_dir_path, filename)\n",
    "                    \n",
    "                    # Move the file to the \"original\" directory\n",
    "                    shutil.move(file_path, destination_path)\n",
    "            print(f\"Moved .tif files from {subcondition_path} to {original_dir_path}\")\n",
    "\n",
    "\n",
    "def ensure_output_dir(output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "def calculate_mean_intensity(path):\n",
    "    \"\"\"Calculate mean intensity of an image.\"\"\"\n",
    "    return io.imread(path).mean()\n",
    "\n",
    "\n",
    "def calculate_protein_concentration(mean_intensity, intercept, slope):\n",
    "    \"\"\"Calculate protein concentration in ng/ul and nM.\"\"\"\n",
    "    conc_ng_ul = (mean_intensity - intercept) / slope\n",
    "    return conc_ng_ul\n",
    "\n",
    "\n",
    "def calculate_protein_concentration_nM(conc_ng_ul, mw_kda):\n",
    "    \"\"\"Convert protein concentration from ng/ul to nM.\"\"\"\n",
    "    conc_nM = (conc_ng_ul * 1e-3) / (mw_kda * 1e3) * 1e9\n",
    "    return conc_nM\n",
    "\n",
    "\n",
    "def calculate_number_of_protein_molecules(protein_mass, mw_kda):\n",
    "    \"\"\"Calculate number of protein molecules.\"\"\"\n",
    "    return (protein_mass * 6e14) / (mw_kda * 1e3)\n",
    "\n",
    "\n",
    "def convert_time_units(time_values_s):\n",
    "    \"\"\"Convert time values from seconds to minutes and hours.\"\"\"\n",
    "    time_values_min = time_values_s / 60\n",
    "    time_values_h = time_values_s / 3600\n",
    "    return time_values_s, time_values_min, time_values_h\n",
    "\n",
    "\n",
    "def process_image(args):\n",
    "    image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition = args\n",
    "    # Read the image into a numpy array\n",
    "    intensity_matrix = io.imread(image_file)\n",
    "\n",
    "    if channel == \"Cy5\":\n",
    "        matrix_to_plot = intensity_matrix\n",
    "        # Use raw intensity for cy5 channel\n",
    "        label = 'Fluorescence Intensity'\n",
    "    else:\n",
    "        # Convert intensity values to protein concentration using the calibration curve\n",
    "        matrix_to_plot = calculate_protein_concentration(intensity_matrix, slope, intercept)\n",
    "        matrix_to_plot = matrix_to_plot / 27000 * 1E6\n",
    "        label = 'Protein concentration (nM)'\n",
    "\n",
    "    # Plot the heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    im = ax.imshow(matrix_to_plot, cmap='gray', interpolation='nearest', vmin=0, vmax=vmax)\n",
    "\n",
    "    if show_scalebar:\n",
    "        plt.colorbar(im, ax=ax, label=label)\n",
    "    plt.title(f\"Time (min): {(i - min_frame) * time_interval * skip_frames / 60:.2f} \\nTime (h): {(i - min_frame) * time_interval * skip_frames / 3600:.2f} \\n{condition} - {subcondition} - {channel}\", fontsize=20)\n",
    "    plt.xlabel('x [µm]')\n",
    "    plt.ylabel('y [µm]')\n",
    "    plt.grid(True, color='#d3d3d3', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # Save the heatmap\n",
    "    heatmap_filename = f\"heatmap_frame_{i}.png\"\n",
    "    heatmap_path = os.path.join(output_directory_path, heatmap_filename)\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def fluorescence_heatmap(data_path, conditions, subconditions, channel, time_interval_list, min_frame, max_frame, vmax, skip_frames=1, calibration_curve_paths=None, show_scalebar=True):\n",
    "    \"\"\"\n",
    "    Reads each image as a matrix, creates, and saves a heatmap representing the normalized pixel-wise fluorescence intensity.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base directory where the images are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): Channel specifying the fluorescence ('cy5' or 'gfp').\n",
    "    - time_interval_list (list): List of time intervals in seconds between frames for each condition.\n",
    "    - min_frame (int): Minimum frame number to start processing from.\n",
    "    - max_frame (int): Maximum frame number to stop processing at.\n",
    "    - vmax (float): Maximum value for color scale in the heatmap.\n",
    "    - skip_frames (int): Interval to skip frames (default is 1, meaning process every frame).\n",
    "    - calibration_curve_paths (list): List of file paths for the calibration curve images.\n",
    "    - show_scalebar (bool): Whether to show the color scale bar in the heatmap.\n",
    "    \"\"\"\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\", \"movies\")\n",
    "    ensure_output_dir(output_data_dir)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        time_interval = time_interval_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            # Determine the directory paths based on the channel\n",
    "            input_directory_path = os.path.join(data_path, condition, subcondition, \"original\")\n",
    "            output_directory_path = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "\n",
    "            # Create the output directory if it doesn't exist, or clear it if it does\n",
    "            if os.path.exists(output_directory_path):\n",
    "                shutil.rmtree(output_directory_path)\n",
    "            os.makedirs(output_directory_path, exist_ok=True)\n",
    "\n",
    "            # Get all .tif files in the folder\n",
    "            image_files = sorted(glob.glob(os.path.join(input_directory_path, f\"*{channel}*.tif\")))[min_frame:max_frame:skip_frames]\n",
    "\n",
    "            # Setup calibration curve for non-cy5 channels\n",
    "            slope, intercept = None, None\n",
    "            if channel != \"Cy5\":\n",
    "                # Calibration curve data and fit\n",
    "                sample_concentration_values = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "\n",
    "                if calibration_curve_paths is None or len(calibration_curve_paths) != len(sample_concentration_values):\n",
    "                    raise ValueError(f\"Mismatch in lengths: {len(calibration_curve_paths)} calibration images, {len(sample_concentration_values)} sample concentrations\")\n",
    "\n",
    "                with mp.Pool(mp.cpu_count()) as pool:\n",
    "                    mean_intensity_calibration = pool.map(calculate_mean_intensity, calibration_curve_paths)\n",
    "                slope, intercept = np.polyfit(sample_concentration_values, mean_intensity_calibration, 1)\n",
    "\n",
    "            # Prepare arguments for multiprocessing\n",
    "            args = [(image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition) for i, image_file in enumerate(image_files, start=min_frame)]\n",
    "\n",
    "            # Use multiprocessing to process images\n",
    "            with mp.Pool(mp.cpu_count()) as pool:\n",
    "                list(tqdm(pool.imap(process_image, args), total=len(args), desc=f\"Processing {condition} - {subcondition}\"))\n",
    "\n",
    "\n",
    "def prepare_conditions(data_path, num_reps):\n",
    "    # List conditions while ignoring 'output_data'\n",
    "    conditions = natsorted([\n",
    "        f for f in os.listdir(data_path) \n",
    "        if os.path.isdir(os.path.join(data_path, f)) and f != 'output_data'\n",
    "    ])\n",
    "    \n",
    "    # Generate subconditions list based on num_reps\n",
    "    subconditions = [f\"Rep{x}\" for x in range(1, num_reps + 1)]\n",
    "    \n",
    "    return conditions, subconditions\n",
    "\n",
    "\n",
    "def process_video_creation(args):\n",
    "    condition, subcondition, images_dir, out_path, frame_rate, max_frame = args\n",
    "\n",
    "    image_files = natsorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found for subcondition {subcondition}.\")\n",
    "        return\n",
    "\n",
    "    # Limit the number of files if max_frame is specified\n",
    "    image_files = image_files[:max_frame] if max_frame is not None else image_files\n",
    "\n",
    "    # Get the resolution of the first image (assuming all images are the same size)\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    video_resolution = (first_image.shape[1], first_image.shape[0])  # Width x Height\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, frame_rate, video_resolution)\n",
    "\n",
    "    for file in tqdm(image_files, desc=f\"Creating video for {condition}\", leave=False):\n",
    "        img = cv2.imread(file)\n",
    "        out.write(img)  # Write the image as a frame in the video\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video saved to {out_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def ensure_output_dir(output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "def process_video_creation(args):\n",
    "    condition, subcondition, images_dir, out_path, frame_rate, max_frame = args\n",
    "\n",
    "    image_files = natsorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found for subcondition {subcondition}.\")\n",
    "        return\n",
    "\n",
    "    # Limit the number of files if max_frame is specified\n",
    "    image_files = image_files[:max_frame] if max_frame is not None else image_files\n",
    "\n",
    "    # Get the resolution of the first image (assuming all images are the same size)\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    video_resolution = (first_image.shape[1], first_image.shape[0])  # Width x Height\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, frame_rate, video_resolution)\n",
    "\n",
    "    for file in tqdm(image_files, desc=f\"Creating video for {condition} - {subcondition}\", leave=False):\n",
    "        img = cv2.imread(file)\n",
    "        out.write(img)  # Write the image as a frame in the video\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video saved to {out_path}\")\n",
    "\n",
    "def create_movies(data_path, conditions, subconditions, channel, frame_rate=30, max_frame=None, delete_temp_dirs=False):\n",
    "    \"\"\"\n",
    "    Creates video files from heatmaps stored in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base path where the heatmaps are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): The specific channel being processed ('cy5' or 'gfp').\n",
    "    - frame_rate (int): Frame rate for the output video. Defaults to 30.\n",
    "    - max_frame (int, optional): Maximum number of frames to be included in the video. If None, all frames are included.\n",
    "    - delete_temp_dirs (bool): If True, deletes temporary heatmap directories after movie creation.\n",
    "    \"\"\"\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\", \"movies\")\n",
    "    ensure_output_dir(output_data_dir)\n",
    "\n",
    "    args_list = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        for subcondition in subconditions:\n",
    "            images_dir = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "            video_filename = f\"{condition}_{subcondition}_{channel}.avi\"\n",
    "            out_path = os.path.join(output_data_dir, video_filename)\n",
    "\n",
    "            # Prepare arguments for multiprocessing\n",
    "            args_list.append((condition, subcondition, images_dir, out_path, frame_rate, max_frame))\n",
    "\n",
    "    # Use multiprocessing to process video creation for all conditions and subconditions\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        list(tqdm(pool.imap(process_video_creation, args_list), total=len(args_list), desc=\"Creating videos\"))\n",
    "\n",
    "    # Delete temporary directories if specified\n",
    "    if delete_temp_dirs:\n",
    "        for condition in conditions:\n",
    "            for subcondition in subconditions:\n",
    "                temp_dir = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "                if os.path.exists(temp_dir):\n",
    "                    shutil.rmtree(temp_dir)\n",
    "                    print(f\"Deleted temporary directory: {temp_dir}\")\n",
    "\n",
    "\n",
    "def quantify_tiffiles(data_path, conditions, subconditions, calibration_curve_paths, mw_kda_list, droplet_volume_list, time_interval_s_list):\n",
    "    \"\"\"Process images to calculate protein concentration and generate plots.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Sort the calibration curve paths\n",
    "    calibration_curve_paths = sorted(calibration_curve_paths)\n",
    "\n",
    "    # Calibration curve data and fit\n",
    "    sample_concentration_values = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        mean_intensity_calibration = pool.map(calculate_mean_intensity, calibration_curve_paths)\n",
    "    slope, intercept = np.polyfit(sample_concentration_values, mean_intensity_calibration, 1)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        # Get condition-specific parameters\n",
    "        mw_kda = mw_kda_list[idx]\n",
    "        droplet_volume = droplet_volume_list[idx]\n",
    "        time_interval_s = time_interval_s_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            # Construct paths based on condition and subcondition\n",
    "            pattern = os.path.join(data_path, condition, subcondition, \"original\", \"img_*********_4x_GFP_000.tif\")\n",
    "            paths = sorted(glob.glob(pattern))\n",
    "\n",
    "            if not paths:\n",
    "                print(f\"No image files found for condition {condition}, subcondition {subcondition}.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate mean intensity for samples\n",
    "            with mp.Pool(mp.cpu_count()) as pool:\n",
    "                mean_intensity_list = list(tqdm(pool.imap(calculate_mean_intensity, paths), total=len(paths), desc=f\"Calculating intensities for {condition} - {subcondition}\"))\n",
    "\n",
    "            # Calculate protein concentrations in ng/ul\n",
    "            protein_concentration_list = [calculate_protein_concentration(intensity, intercept, slope) for intensity in mean_intensity_list]\n",
    "\n",
    "            # Convert to nM\n",
    "            protein_concentration_nM_list = [calculate_protein_concentration_nM(conc_ng_ul, mw_kda) for conc_ng_ul in protein_concentration_list]\n",
    "\n",
    "            # Normalize intensities and concentrations\n",
    "            min_intensity = min(mean_intensity_list)\n",
    "            mean_intensity_list = np.array(mean_intensity_list) - min_intensity\n",
    "            protein_concentration_list = np.array(protein_concentration_list) - min(protein_concentration_list)\n",
    "            protein_concentration_nM_list = np.array(protein_concentration_nM_list) - min(protein_concentration_nM_list)\n",
    "\n",
    "            # Time values\n",
    "            time_values_s = np.arange(len(mean_intensity_list)) * time_interval_s\n",
    "            time_values_s, time_values_min, time_values_h = convert_time_units(time_values_s)\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                \"Condition\": condition,\n",
    "                \"Subcondition\": subcondition,\n",
    "                \"Time_s\": time_values_s,\n",
    "                \"Time_min\": time_values_min,\n",
    "                \"Time_h\": time_values_h,\n",
    "                \"Mean Intensity\": mean_intensity_list,\n",
    "                \"Protein Concentration_ng_ul\": protein_concentration_list,\n",
    "                \"Protein Concentration_nM\": protein_concentration_nM_list\n",
    "            })\n",
    "\n",
    "            # Calculate number of protein molecules\n",
    "            protein_mass_list = df[\"Protein Concentration_ng_ul\"] * droplet_volume\n",
    "            df[\"Number of Protein Molecules\"] = [calculate_number_of_protein_molecules(mass, mw_kda) for mass in protein_mass_list]\n",
    "\n",
    "            # Calculate rate of change of protein molecules\n",
    "            t_vals = np.linspace(0, (len(df) - 1) * time_interval_s, len(df))\n",
    "            dp_dt = gaussian_filter1d(np.gradient(df[\"Number of Protein Molecules\"], t_vals), sigma=2)\n",
    "            df[\"Rate of Change of Number of Protein Molecules (PM/s)\"] = dp_dt\n",
    "\n",
    "            # Append the data for this condition and subcondition to the list\n",
    "            all_data.append(df)\n",
    "\n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Calculate mean for each condition across subconditions\n",
    "    mean_df = combined_df.groupby([\"Condition\", \"Time_s\", \"Time_min\", \"Time_h\"]).mean(numeric_only=True).reset_index()\n",
    "\n",
    "    # Set the output directory within the data path\n",
    "    output_dir = os.path.join(data_path, \"output_data\")\n",
    "    ensure_output_dir(output_dir)\n",
    "\n",
    "    # Save combined results to CSV\n",
    "    combined_csv_path = os.path.join(output_dir, \"combined_experiment.csv\")\n",
    "    combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "    # Save mean results to CSV\n",
    "    mean_csv_path = os.path.join(output_dir, \"mean_experiment.csv\")\n",
    "    mean_df.to_csv(mean_csv_path, index=False)\n",
    "\n",
    "    # Plotting\n",
    "    plot_results(combined_df, mean_df, output_dir, sample_concentration_values, mean_intensity_calibration, slope, intercept)\n",
    "\n",
    "    return combined_csv_path, mean_csv_path\n",
    "\n",
    "\n",
    "def plot_results(df, mean_df, output_dir, sample_concentration_values, mean_intensity_calibration, slope, intercept):\n",
    "    \"\"\"Generate plots based on the processed data.\"\"\"\n",
    "    # Create subdirectories for plots\n",
    "    single_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"single_plots\")\n",
    "    combined_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"combined_plots\")\n",
    "    mean_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"mean_plots\")\n",
    "    ensure_output_dir(single_plot_dir)\n",
    "    ensure_output_dir(combined_plot_dir)\n",
    "    ensure_output_dir(mean_plot_dir)\n",
    "\n",
    "    # Plot calibration curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sample_concentration_values, mean_intensity_calibration, 'o', label='Data points', linewidth=0.75, markersize=5)\n",
    "    plt.plot(sample_concentration_values, slope * np.array(sample_concentration_values) + intercept, 'r-', label=f'Fit: y = {slope:.2f}x + {intercept:.2f}', linewidth=0.75)\n",
    "    plt.title('Mean Intensity vs Protein Concentration')\n",
    "    plt.xlabel('Protein Concentration (ug/ml)')\n",
    "    plt.ylabel('Mean Intensity')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(single_plot_dir, 'mean_intensity_vs_protein_concentration.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot calibration curve (log scale)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sample_concentration_values, mean_intensity_calibration, 'o', label='Data points', linewidth=0.75, markersize=5)\n",
    "    plt.plot(sample_concentration_values, slope * np.array(sample_concentration_values) + intercept, 'r-', label=f'Fit: y = {slope:.2f}x + {intercept:.2f}', linewidth=0.75)\n",
    "    plt.title('Mean Intensity vs Protein Concentration (Log Scale)')\n",
    "    plt.xlabel('Protein Concentration (ug/ml)')\n",
    "    plt.ylabel('Mean Intensity')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(single_plot_dir, 'mean_intensity_vs_protein_concentration_log.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Time units and concentration units to plot\n",
    "    time_units = [(\"Time_s\", \"Time_s\"), (\"Time_min\", \"Time_min\"), (\"Time_h\", \"Time_h\")]\n",
    "    protein_concentration_units = [\n",
    "        (\"Protein Concentration_ng_ul\", \"Protein Concentration_ng_ul\"),\n",
    "        (\"Protein Concentration_nM\", \"Protein Concentration_nM\"),\n",
    "        (\"Number of Protein Molecules\", \"Number of Protein Molecules\")\n",
    "    ]\n",
    "\n",
    "    # Plot protein concentration over time for each time and concentration unit\n",
    "    for time_unit, time_label in time_units:\n",
    "        for conc_unit, conc_label in protein_concentration_units:\n",
    "            # Individual plots for each condition and subcondition\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                # Create a directory for each condition's single plots\n",
    "                condition_single_plot_dir = os.path.join(single_plot_dir, f\"{condition}_single_plots\")\n",
    "                ensure_output_dir(condition_single_plot_dir)\n",
    "\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "                    plt.title(f'{conc_label} vs {time_label} for {condition} {subcondition}')\n",
    "                    plt.xlabel(time_label)\n",
    "                    plt.ylabel(conc_label)\n",
    "                    plt.legend()\n",
    "                    plt.grid(True)\n",
    "                    plt.savefig(os.path.join(condition_single_plot_dir, f'{condition}_{subcondition}_{conc_label}_vs_{time_label}.png'))\n",
    "                    plt.close()\n",
    "\n",
    "            # Combined plots for all conditions and subconditions\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Combined {conc_label} vs {time_label} for all conditions')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(combined_plot_dir, f'combined_{conc_label}_vs_{time_label}.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Combined plots for all conditions and subconditions (log scale)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Combined {conc_label} vs {time_label} for all conditions (Log Scale)')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(combined_plot_dir, f'combined_{conc_label}_vs_{time_label}_log.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Mean plots for each condition\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in mean_df[\"Condition\"].unique():\n",
    "                condition_mean_data = mean_df[mean_df[\"Condition\"] == condition]\n",
    "                plt.plot(condition_mean_data[time_unit], condition_mean_data[conc_unit], 'o-', label=f'{condition} Mean', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Mean {conc_label} vs {time_label} for each condition')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(mean_plot_dir, f'mean_{conc_label}_vs_{time_label}.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Mean plots for each condition (log scale)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in mean_df[\"Condition\"].unique():\n",
    "                condition_mean_data = mean_df[mean_df[\"Condition\"] == condition]\n",
    "                plt.plot(condition_mean_data[time_unit], condition_mean_data[conc_unit], 'o-', label=f'{condition} Mean', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Mean {conc_label} vs {time_label} for each condition (Log Scale)')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(mean_plot_dir, f'mean_{conc_label}_vs_{time_label}_log.png'))\n",
    "            plt.close()\n",
    "\n",
    "    # Plot rate of change of protein molecules\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for condition in df[\"Condition\"].unique():\n",
    "        for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "            condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "            plt.plot(condition_data[\"Time_h\"], condition_data[\"Rate of Change of Number of Protein Molecules (PM/s)\"], 'o', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "    plt.title('Rate of Change of Number of Protein Molecules vs Time_h')\n",
    "    plt.xlabel('Time_h')\n",
    "    plt.ylabel('Rate of Change (PM/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(combined_plot_dir, 'rate_of_change_of_protein_molecules_vs_time_h.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot rate of change of protein molecules (log scale)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for condition in df[\"Condition\"].unique():\n",
    "        for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "            condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "            plt.plot(condition_data[\"Time_h\"], condition_data[\"Rate of Change of Number of Protein Molecules (PM/s)\"], 'o', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "    plt.title('Rate of Change of Number of Protein Molecules vs Time_h (Log Scale)')\n",
    "    plt.xlabel('Time_h')\n",
    "    plt.ylabel('Rate of Change (PM/s)')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(combined_plot_dir, 'rate_of_change_of_protein_molecules_vs_time_h_log.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_combined_heatmap_movie_custom_grid(data_path, conditions, subconditions, channel, grid_rows=None, grid_cols=None, frame_rate=30, delete_temp_dirs=False):\n",
    "    \"\"\"\n",
    "    Combines heatmaps from different conditions and subconditions into a single video.\n",
    "    Allows specifying the number of grid rows and columns or uses an adaptive layout based on subconditions.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base path where the heatmaps are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): The specific channel being processed ('cy5' or 'gfp').\n",
    "    - grid_rows (int, optional): Number of rows in the grid. If None, calculated adaptively.\n",
    "    - grid_cols (int, optional): Number of columns in the grid. If None, calculated adaptively.\n",
    "    - frame_rate (int): Frame rate for the output video. Defaults to 30.\n",
    "    - delete_temp_dirs (bool): If True, deletes temporary heatmap directories after movie creation.\n",
    "    \"\"\"\n",
    "    # Determine grid dimensions if not provided\n",
    "    total_plots = len(conditions) * len(subconditions)\n",
    "    \n",
    "    if grid_rows is None or grid_cols is None:\n",
    "        if len(subconditions) == 1:\n",
    "            # Use a rectangular grid with more columns than rows when only one subcondition\n",
    "            grid_cols = int(np.ceil(np.sqrt(total_plots)))\n",
    "            grid_rows = int(np.ceil(total_plots / grid_cols))\n",
    "            \n",
    "            # Adjust columns and rows to minimize blank spaces\n",
    "            while grid_cols * grid_rows >= total_plots:\n",
    "                if (grid_cols - 1) * grid_rows >= total_plots:\n",
    "                    grid_cols -= 1\n",
    "                elif grid_cols * (grid_rows - 1) >= total_plots:\n",
    "                    grid_rows -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            # Use a column-row layout with conditions in columns and subconditions in rows\n",
    "            grid_rows = len(subconditions)\n",
    "            grid_cols = len(conditions)\n",
    "    \n",
    "    # Define the output directory for temporary images\n",
    "    temp_img_dir = os.path.join(data_path, \"output_data\", \"temp_images\")\n",
    "    ensure_output_dir(temp_img_dir)\n",
    "\n",
    "    # Determine the number of frames based on the first condition and subcondition\n",
    "    sample_image_dir = os.path.join(data_path, \"output_data\", \"movies\", f\"{conditions[0]}_{subconditions[0]}_heatmaps_{channel}\")\n",
    "    sample_image_files = natsorted(glob.glob(os.path.join(sample_image_dir, \"*.png\")))\n",
    "    num_frames = len(sample_image_files)\n",
    "\n",
    "    if num_frames == 0:\n",
    "        print(f\"No frames to process. Check if the directories exist and contain images.\")\n",
    "        return\n",
    "\n",
    "    # Loop through each frame\n",
    "    for frame_index in tqdm(range(num_frames), desc=\"Creating combined frames\"):\n",
    "        fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(grid_cols * 6, grid_rows * 6))\n",
    "        plt.subplots_adjust(hspace=0.1, wspace=0.1)  # Adjust spacing\n",
    "\n",
    "        # Ensure axes is always 2D\n",
    "        if grid_rows == 1 and grid_cols == 1:\n",
    "            axes = np.array([[axes]])\n",
    "        elif grid_rows == 1 or grid_cols == 1:\n",
    "            axes = np.array(axes).reshape(grid_rows, grid_cols)\n",
    "\n",
    "        plot_index = 0\n",
    "\n",
    "        # Loop through each condition and subcondition\n",
    "        for col_idx, condition in enumerate(conditions):\n",
    "            for row_idx, subcondition in enumerate(subconditions):\n",
    "                # Determine the image path\n",
    "                images_dir = os.path.join(data_path, \"output_data\", \"movies\", f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "                image_files = natsorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "                if frame_index < len(image_files):\n",
    "                    image_path = image_files[frame_index]\n",
    "                    img = io.imread(image_path)\n",
    "\n",
    "                    # Plot the image in the appropriate subplot\n",
    "                    ax = axes[row_idx if len(subconditions) > 1 else plot_index // grid_cols,\n",
    "                              col_idx if len(subconditions) > 1 else plot_index % grid_cols]\n",
    "                    ax.imshow(img, cmap='gray', vmin=0, vmax=img.max())\n",
    "                    ax.axis('off')  # Remove axes\n",
    "\n",
    "                    plot_index += 1\n",
    "\n",
    "        # Turn off any unused subplots\n",
    "        for ax in axes.flatten()[plot_index:]:\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Save the combined frame\n",
    "        combined_image_path = os.path.join(temp_img_dir, f\"combined_frame_{frame_index:04d}.png\")\n",
    "        plt.savefig(combined_image_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Compile the images into a video using OpenCV\n",
    "    combined_image_files = natsorted(glob.glob(os.path.join(temp_img_dir, \"combined_frame_*.png\")))\n",
    "\n",
    "    # Get the resolution of the first image\n",
    "    first_image = cv2.imread(combined_image_files[0])\n",
    "    height, width, layers = first_image.shape\n",
    "    video_resolution = (width, height)\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\")\n",
    "    output_filename = f\"combined_heatmap_movie_{channel}.avi\"\n",
    "    output_file = os.path.join(output_data_dir, output_filename)\n",
    "    ensure_output_dir(output_data_dir)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, frame_rate, video_resolution)\n",
    "\n",
    "    for image_file in combined_image_files:\n",
    "        img = cv2.imread(image_file)\n",
    "        out.write(img)  # Write the image as a frame in the video\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Combined video saved to {output_file}\")\n",
    "\n",
    "    # Clean up temporary images\n",
    "    shutil.rmtree(temp_img_dir)\n",
    "\n",
    "    # Delete temporary directories if specified\n",
    "    if delete_temp_dirs:\n",
    "        for condition in conditions:\n",
    "            for subcondition in subconditions:\n",
    "                temp_dir = os.path.join(data_path, \"output_data\", \"movies\", f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "                if os.path.exists(temp_dir):\n",
    "                    shutil.rmtree(temp_dir)\n",
    "                    print(f\"Deleted temporary directory: {temp_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Read the data and reorganize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved .tif files from ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/A/Rep1 to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/A/Rep1/original\n",
      "Moved .tif files from ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/C/Rep1 to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/C/Rep1/original\n",
      "Moved .tif files from ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/Control/Rep1 to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/Control/Rep1/original\n",
      "Moved .tif files from ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/E/Rep1 to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/E/Rep1/original\n",
      "Moved .tif files from ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/F/Rep1 to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/F/Rep1/original\n",
      "Moved .tif files from ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/G/Rep1 to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/G/Rep1/original\n",
      "Moved .tif files from ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/H/Rep1 to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/H/Rep1/original\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/\"\n",
    "number_reps = 1\n",
    "conditions, subconditions = prepare_conditions(data_path, number_reps)\n",
    "\n",
    "# Define calibration curve paths\n",
    "calibration_curve_paths = sorted(glob.glob(\"../../data/calibration_curve/***ugml.tif\"))\n",
    "reorgTiffsToOriginal(data_path, conditions, subconditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.- Process gfp channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing A - Rep1: 100%|██████████| 86/86 [00:18<00:00,  4.64it/s]\n",
      "Processing C - Rep1: 100%|██████████| 86/86 [00:17<00:00,  4.92it/s]\n",
      "Processing Control - Rep1: 100%|██████████| 86/86 [00:16<00:00,  5.17it/s]\n",
      "Processing E - Rep1: 100%|██████████| 86/86 [00:17<00:00,  5.06it/s]\n",
      "Processing F - Rep1: 100%|██████████| 86/86 [00:18<00:00,  4.71it/s]\n",
      "Processing G - Rep1: 100%|██████████| 86/86 [00:16<00:00,  5.35it/s]\n",
      "Processing H - Rep1: 100%|██████████| 86/86 [00:17<00:00,  4.84it/s]\n"
     ]
    }
   ],
   "source": [
    "channel = \"GFP\"\n",
    "time_interval_list = [60] * len(conditions)  # time intervals in seconds between frames for each condition\n",
    "min_frame = 0\n",
    "max_frame = None\n",
    "vmax = 500  # Set vmax based on your data's expected concentration range\n",
    "skip_frames = 32 #### CHANGE \n",
    "\n",
    "\n",
    "# Call the function\n",
    "fluorescence_heatmap(data_path, conditions, subconditions, channel, time_interval_list, min_frame, max_frame, vmax, skip_frames, calibration_curve_paths, show_scalebar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            3it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/H_Rep1_GFP.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/Control_Rep1_GFP.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/A_Rep1_GFP.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/G_Rep1_GFP.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/F_Rep1_GFP.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/C_Rep1_GFP.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/E_Rep1_GFP.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating videos: 100%|██████████| 7/7 [00:18<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "frame_rate = 15  # frames per second\n",
    "create_movies(data_path, conditions, subconditions, channel, frame_rate=frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating combined frames: 100%|██████████| 86/86 [06:09<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/combined_heatmap_movie_GFP.avi\n"
     ]
    }
   ],
   "source": [
    "create_combined_heatmap_movie_custom_grid(data_path, conditions, subconditions, channel, grid_rows=2, grid_cols=5, frame_rate=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.- Process cy5 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing A - Rep1: 100%|██████████| 86/86 [00:25<00:00,  3.36it/s]\n",
      "Processing C - Rep1: 100%|██████████| 86/86 [00:15<00:00,  5.44it/s]\n",
      "Processing Control - Rep1: 100%|██████████| 86/86 [00:13<00:00,  6.50it/s]\n",
      "Processing E - Rep1: 100%|██████████| 86/86 [00:14<00:00,  5.95it/s]\n",
      "Processing F - Rep1: 100%|██████████| 86/86 [00:14<00:00,  6.06it/s]\n",
      "Processing G - Rep1: 100%|██████████| 86/86 [00:13<00:00,  6.21it/s]\n",
      "Processing H - Rep1: 100%|██████████| 86/86 [00:13<00:00,  6.25it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "channel = \"Cy5\"\n",
    "min_frame = 0\n",
    "max_frame = None\n",
    "vmax = 14E3  # Set vmax based on your data's expected concentration range\n",
    "skip_frames = 32\n",
    "\n",
    "\n",
    "# Call the function\n",
    "fluorescence_heatmap(data_path, conditions, subconditions, channel, time_interval_list, min_frame, max_frame, vmax, skip_frames, calibration_curve_paths, show_scalebar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            7it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/H_Rep1_Cy5.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/Control_Rep1_Cy5.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating video for F - Rep1: 100%|██████████| 86/86 [00:18<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/G_Rep1_Cy5.avi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/F_Rep1_Cy5.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating video for E - Rep1: 100%|██████████| 86/86 [00:18<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/A_Rep1_Cy5.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/E_Rep1_Cy5.avi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating videos:  14%|█▍        | 1/7 [00:18<01:53, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/movies/C_Rep1_Cy5.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating videos: 100%|██████████| 7/7 [00:19<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# frame_rate = 1  # frames per second\n",
    "create_movies(data_path, conditions, subconditions, channel, frame_rate=frame_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating combined frames: 100%|██████████| 86/86 [06:23<00:00,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined video saved to ../../data/080224-ACEFGH-RT/4txtl_1mt_2dna/output_data/combined_heatmap_movie_Cy5.avi\n"
     ]
    }
   ],
   "source": [
    "create_combined_heatmap_movie_custom_grid(data_path, conditions, subconditions, channel, grid_rows=2, grid_cols=5, frame_rate=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Generate .csv files with gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No image files found for condition A, subcondition Rep1.\n",
      "No image files found for condition C, subcondition Rep1.\n",
      "No image files found for condition Control, subcondition Rep1.\n",
      "No image files found for condition E, subcondition Rep1.\n",
      "No image files found for condition F, subcondition Rep1.\n",
      "No image files found for condition G, subcondition Rep1.\n",
      "No image files found for condition H, subcondition Rep1.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m time_interval_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m600\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(conditions)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Quantify tiff files\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mquantify_tiffiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubconditions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalibration_curve_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmw_kda_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdroplet_volume_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_interval_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 383\u001b[0m, in \u001b[0;36mquantify_tiffiles\u001b[0;34m(data_path, conditions, subconditions, calibration_curve_paths, mw_kda_list, droplet_volume_list, time_interval_s_list)\u001b[0m\n\u001b[1;32m    380\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Combine all data into a single DataFrame\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# Calculate mean for each condition across subconditions\u001b[39;00m\n\u001b[1;32m    386\u001b[0m mean_df \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCondition\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime_s\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime_min\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime_h\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "\n",
    "mw_kda_list = [100] * len(conditions)\n",
    "droplet_volume_list = [2] * len(conditions)\n",
    "time_interval_list = [60] * len(conditions)\n",
    "\n",
    "# Quantify tiff files\n",
    "quantify_tiffiles(data_path, conditions, subconditions, calibration_curve_paths, mw_kda_list, droplet_volume_list, time_interval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
