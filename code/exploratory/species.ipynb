{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import minimize\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import norm\n",
    "\n",
    "# utilities\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('fork', force=True)\n",
    "from multiprocessing import Pool\n",
    "from ipywidgets import interact, FloatSlider, Layout, interactive\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import itertools\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorgTiffsToOriginal(data_path, conditions, subconditions):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_path (_type_): _description_\n",
    "        conditions (_type_): _description_\n",
    "        subconditions (_type_): _description_\n",
    "        \n",
    "        \n",
    "    Activate when you have your subconditions inside the conditions folder. \n",
    "    This function renames the subconditions as PosX and moves the raw data do \"original\" folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    for condition in conditions:\n",
    "        # Get the actual subconditions in the directory\n",
    "        actual_subconditions = [name for name in os.listdir(os.path.join(data_path, condition)) if os.path.isdir(os.path.join(data_path, condition, name))]\n",
    "        \n",
    "        # Rename the actual subconditions to match the subconditions in your list\n",
    "        for i, actual_subcondition in enumerate(sorted(actual_subconditions)):\n",
    "            os.rename(os.path.join(data_path, condition, actual_subcondition), os.path.join(data_path, condition, subconditions[i]))\n",
    "        \n",
    "        for subcondition in subconditions:\n",
    "            # Construct the path to the subcondition directory\n",
    "            subcondition_path = os.path.join(data_path, condition, subcondition)\n",
    "            \n",
    "            # Create the path for the \"original\" directory within the subcondition directory\n",
    "            original_dir_path = os.path.join(subcondition_path, \"original\")\n",
    "            \n",
    "            # Always create the \"original\" directory\n",
    "            os.makedirs(original_dir_path, exist_ok=True)\n",
    "            \n",
    "            # Iterate over all files in the subcondition directory\n",
    "            for filename in os.listdir(subcondition_path):\n",
    "                # Check if the file is a .tif file\n",
    "                if filename.endswith(\".tif\"):\n",
    "                    # Construct the full path to the file\n",
    "                    file_path = os.path.join(subcondition_path, filename)\n",
    "                    \n",
    "                    # Construct the path to move the file to\n",
    "                    destination_path = os.path.join(original_dir_path, filename)\n",
    "                    \n",
    "                    # Move the file to the \"original\" directory\n",
    "                    shutil.move(file_path, destination_path)\n",
    "            print(f\"Moved .tif files from {subcondition_path} to {original_dir_path}\")\n",
    "\n",
    "\n",
    "def ensure_output_dir(output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "def calculate_mean_intensity(path):\n",
    "    \"\"\"Calculate mean intensity of an image.\"\"\"\n",
    "    return io.imread(path).mean()\n",
    "\n",
    "def calculate_protein_concentration(mean_intensity, intercept, slope):\n",
    "    \"\"\"Calculate protein concentration in ng/ul and nM.\"\"\"\n",
    "    conc_ng_ul = (mean_intensity - intercept) / slope\n",
    "    return conc_ng_ul\n",
    "\n",
    "def calculate_protein_concentration_nM(conc_ng_ul, mw_kda):\n",
    "    \"\"\"Convert protein concentration from ng/ul to nM.\"\"\"\n",
    "    conc_nM = (conc_ng_ul * 1e-3) / (mw_kda * 1e3) * 1e9\n",
    "    return conc_nM\n",
    "\n",
    "def calculate_number_of_protein_molecules(protein_mass, mw_kda):\n",
    "    \"\"\"Calculate number of protein molecules.\"\"\"\n",
    "    return (protein_mass * 6e14) / (mw_kda * 1e3)\n",
    "\n",
    "def convert_time_units(time_values_s):\n",
    "    \"\"\"Convert time values from seconds to minutes and hours.\"\"\"\n",
    "    time_values_min = time_values_s / 60\n",
    "    time_values_h = time_values_s / 3600\n",
    "    return time_values_s, time_values_min, time_values_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_conditions(data_path, num_reps):\n",
    "    # List conditions while ignoring 'output_data'\n",
    "    conditions = natsorted([\n",
    "        f for f in os.listdir(data_path) \n",
    "        if os.path.isdir(os.path.join(data_path, f)) and f != 'output_data'\n",
    "    ])\n",
    "    \n",
    "    # Generate subconditions list based on num_reps\n",
    "    subconditions = [f\"Rep{x}\" for x in range(1, num_reps + 1)]\n",
    "    \n",
    "    return conditions, subconditions\n",
    "\n",
    "# Example usage\n",
    "data_path = \"../../data/072224-species_30C/2ultxtl-1uldna-0p5ulMT_2/\"\n",
    "conditions, subconditions = prepare_conditions(data_path, 1)\n",
    "\n",
    "# Define calibration curve paths\n",
    "calibration_curve_paths = sorted(glob.glob(\"../../data/calibration_curve/***ugml.tif\"))\n",
    "reorgTiffsToOriginal(data_path, conditions, subconditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing AcSu - Rep1: 100%|██████████| 10/10 [00:03<00:00,  2.83it/s]\n",
      "Processing AcSu2 - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "Processing AdPa - Rep1: 100%|██████████| 10/10 [00:03<00:00,  2.99it/s]\n",
      "Processing BleSto - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]\n",
      "Processing DiPu - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.12it/s]\n",
      "Processing HeAl - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n",
      "Processing Kif5 - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.18it/s]\n",
      "Processing NaGr - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.41it/s]\n",
      "Processing ThTr - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n",
      "Processing TiLa - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.31it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_image(args):\n",
    "    image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition = args\n",
    "    # Read the image into a numpy array\n",
    "    intensity_matrix = io.imread(image_file)\n",
    "\n",
    "    if channel == \"cy5\":\n",
    "        matrix_to_plot = intensity_matrix\n",
    "        # Use raw intensity for cy5 channel\n",
    "        label = 'Fluorescence Intensity'\n",
    "    else:\n",
    "        # Convert intensity values to protein concentration using the calibration curve\n",
    "        matrix_to_plot = calculate_protein_concentration(intensity_matrix, slope, intercept)\n",
    "        matrix_to_plot = matrix_to_plot / 27000 * 1E6 \n",
    "        label = 'Protein concentration (nM)'\n",
    "\n",
    "    # Plot the heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    im = ax.imshow(matrix_to_plot, cmap='gray', interpolation='nearest', vmin=0, vmax=vmax)\n",
    "\n",
    "    if show_scalebar:\n",
    "        plt.colorbar(im, ax=ax, label=label)\n",
    "    plt.title(f\"Time (min): {(i - min_frame) * time_interval * skip_frames / 60:.2f} \\nTime (h): {(i - min_frame) * time_interval * skip_frames / 3600:.2f} \\n{condition} - {subcondition} - {channel}\", fontsize=14)\n",
    "    plt.xlabel('x [µm]')\n",
    "    plt.ylabel('y [µm]')\n",
    "    plt.grid(True, color='#d3d3d3', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "    # Save the heatmap\n",
    "    heatmap_filename = f\"heatmap_frame_{i}.png\"\n",
    "    heatmap_path = os.path.join(output_directory_path, heatmap_filename)\n",
    "    plt.savefig(heatmap_path, bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def fluorescence_heatmap(data_path, conditions, subconditions, channel, time_interval_list, min_frame, max_frame, vmax, skip_frames=1, calibration_curve_paths=None, show_scalebar=True):\n",
    "    \"\"\"\n",
    "    Reads each image as a matrix, creates, and saves a heatmap representing the normalized pixel-wise fluorescence intensity.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base directory where the images are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): Channel specifying the fluorescence ('cy5' or 'gfp').\n",
    "    - time_interval_list (list): List of time intervals in seconds between frames for each condition.\n",
    "    - min_frame (int): Minimum frame number to start processing from.\n",
    "    - max_frame (int): Maximum frame number to stop processing at.\n",
    "    - vmax (float): Maximum value for color scale in the heatmap.\n",
    "    - skip_frames (int): Interval to skip frames (default is 1, meaning process every frame).\n",
    "    - calibration_curve_paths (list): List of file paths for the calibration curve images.\n",
    "    - show_scalebar (bool): Whether to show the color scale bar in the heatmap.\n",
    "    \"\"\"\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\", \"movies\")\n",
    "    ensure_output_dir(output_data_dir)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        time_interval = time_interval_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            # Determine the directory paths based on the channel\n",
    "            input_directory_path = os.path.join(data_path, condition, subcondition, \"original\")\n",
    "            output_directory_path = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "\n",
    "            # Create the output directory if it doesn't exist, or clear it if it does\n",
    "            if os.path.exists(output_directory_path):\n",
    "                shutil.rmtree(output_directory_path)\n",
    "            os.makedirs(output_directory_path, exist_ok=True)\n",
    "\n",
    "            # Get all .tif files in the folder\n",
    "            image_files = sorted(glob.glob(os.path.join(input_directory_path, f\"*{channel}*.tif\")))[min_frame:max_frame:skip_frames]\n",
    "\n",
    "            # Setup calibration curve for non-cy5 channels\n",
    "            slope, intercept = None, None\n",
    "            if channel != \"cy5\":\n",
    "                # Calibration curve data and fit\n",
    "                sample_concentration_values = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "\n",
    "                if calibration_curve_paths is None or len(calibration_curve_paths) != len(sample_concentration_values):\n",
    "                    raise ValueError(f\"Mismatch in lengths: {len(calibration_curve_paths)} calibration images, {len(sample_concentration_values)} sample concentrations\")\n",
    "\n",
    "                with mp.Pool(mp.cpu_count()) as pool:\n",
    "                    mean_intensity_calibration = pool.map(calculate_mean_intensity, calibration_curve_paths)\n",
    "                slope, intercept = np.polyfit(sample_concentration_values, mean_intensity_calibration, 1)\n",
    "\n",
    "            # Prepare arguments for multiprocessing\n",
    "            args = [(image_file, output_directory_path, channel, slope, intercept, vmax, time_interval, i, show_scalebar, min_frame, skip_frames, condition, subcondition) for i, image_file in enumerate(image_files, start=min_frame)]\n",
    "\n",
    "            # Use multiprocessing to process images\n",
    "            with mp.Pool(mp.cpu_count()) as pool:\n",
    "                list(tqdm(pool.imap(process_image, args), total=len(args), desc=f\"Processing {condition} - {subcondition}\"))\n",
    "\n",
    "# Example usage\n",
    "\n",
    "channel = \"gfp\"\n",
    "time_interval_list = [120] * len(conditions)  # time intervals in seconds between frames for each condition\n",
    "min_frame = 0\n",
    "max_frame = None\n",
    "vmax = 500  # Set vmax based on your data's expected concentration range\n",
    "skip_frames = 64\n",
    "\n",
    "\n",
    "# Call the function\n",
    "fluorescence_heatmap(data_path, conditions, subconditions, channel, time_interval_list, min_frame, max_frame, vmax, skip_frames, calibration_curve_paths, show_scalebar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing AcSu - Rep1: 100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "Processing AcSu2 - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.30it/s]\n",
      "Processing AdPa - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.36it/s]\n",
      "Processing BleSto - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.34it/s]\n",
      "Processing DiPu - Rep1: 100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n",
      "Processing HeAl - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.60it/s]\n",
      "Processing Kif5 - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.43it/s]\n",
      "Processing NaGr - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.71it/s]\n",
      "Processing ThTr - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.54it/s]\n",
      "Processing TiLa - Rep1: 100%|██████████| 10/10 [00:02<00:00,  3.35it/s]\n"
     ]
    }
   ],
   "source": [
    "channel = \"cy5\"\n",
    "time_interval_list = [120] * len(conditions)  # time intervals in seconds between frames for each condition\n",
    "min_frame = 0\n",
    "max_frame = None\n",
    "vmax = 14E3  # Set vmax based on your data's expected concentration range\n",
    "skip_frames = 64\n",
    "\n",
    "# Call the function\n",
    "fluorescence_heatmap(data_path, conditions, subconditions, channel, time_interval_list, min_frame, max_frame, vmax, skip_frames, calibration_curve_paths, show_scalebar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_creation(args):\n",
    "    condition, subcondition, images_dir, out_path, frame_rate, max_frame = args\n",
    "\n",
    "    image_files = natsorted(glob.glob(os.path.join(images_dir, \"*.png\")))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found for subcondition {subcondition}.\")\n",
    "        return\n",
    "\n",
    "    # Limit the number of files if max_frame is specified\n",
    "    image_files = image_files[:max_frame] if max_frame is not None else image_files\n",
    "\n",
    "    # Get the resolution of the first image (assuming all images are the same size)\n",
    "    first_image = cv2.imread(image_files[0])\n",
    "    video_resolution = (first_image.shape[1], first_image.shape[0])  # Width x Height\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, frame_rate, video_resolution)\n",
    "\n",
    "    for file in tqdm(image_files, desc=f\"Creating video for {condition}\", leave=False):\n",
    "        img = cv2.imread(file)\n",
    "        out.write(img)  # Write the image as a frame in the video\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video saved to {out_path}\")\n",
    "\n",
    "def create_movies(data_path, conditions, subconditions, channel, frame_rate=30, max_frame=None):\n",
    "    \"\"\"\n",
    "    Creates video files from heatmaps stored in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    - data_path (str): Base path where the heatmaps are stored.\n",
    "    - conditions (list): List of conditions defining subdirectories within the data path.\n",
    "    - subconditions (list): List of subconditions defining further subdirectories.\n",
    "    - channel (str): The specific channel being processed ('cy5' or 'gfp').\n",
    "    - frame_rate (int): Frame rate for the output video. Defaults to 30.\n",
    "    - max_frame (int, optional): Maximum number of frames to be included in the video. If None, all frames are included.\n",
    "    \"\"\"\n",
    "    output_data_dir = os.path.join(data_path, \"output_data\", \"movies\")\n",
    "\n",
    "    for condition in conditions:\n",
    "        args_list = []\n",
    "        for subcondition in subconditions:\n",
    "            images_dir = os.path.join(output_data_dir, f\"{condition}_{subcondition}_heatmaps_{channel}\")\n",
    "            video_filename = f\"{condition}_{subcondition}_{channel}.avi\"\n",
    "            out_path = os.path.join(output_data_dir, video_filename)\n",
    "\n",
    "            # Prepare arguments for multiprocessing\n",
    "            args_list.append((condition, subcondition, images_dir, out_path, frame_rate, max_frame))\n",
    "\n",
    "        # Use multiprocessing to process video creation for subconditions of a single condition\n",
    "        with mp.Pool(mp.cpu_count()) as pool:\n",
    "            list(tqdm(pool.imap(process_video_creation, args_list), total=len(args_list), desc=f\"Creating videos for condition {condition}\", leave=True))\n",
    "\n",
    "# Example usage\n",
    "frame_rate = 1  # frames per second\n",
    "\n",
    "create_movies(data_path, conditions, subconditions, channel, frame_rate=frame_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quantify_tiffiles(data_path, conditions, subconditions, calibration_curve_paths, mw_kda_list, droplet_volume_list, time_interval_s_list):\n",
    "    \"\"\"Process images to calculate protein concentration and generate plots.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Sort the calibration curve paths\n",
    "    calibration_curve_paths = sorted(calibration_curve_paths)\n",
    "\n",
    "    # Calibration curve data and fit\n",
    "    sample_concentration_values = [0, 2, 5, 10, 20, 40, 80, 160, 320]\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        mean_intensity_calibration = pool.map(calculate_mean_intensity, calibration_curve_paths)\n",
    "    slope, intercept = np.polyfit(sample_concentration_values, mean_intensity_calibration, 1)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        # Get condition-specific parameters\n",
    "        mw_kda = mw_kda_list[idx]\n",
    "        droplet_volume = droplet_volume_list[idx]\n",
    "        time_interval_s = time_interval_s_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            # Construct paths based on condition and subcondition\n",
    "            pattern = os.path.join(data_path, condition, subcondition, \"original\", \"img_*********_gfp-4x_000.tif\")\n",
    "            paths = sorted(glob.glob(pattern))\n",
    "\n",
    "            if not paths:\n",
    "                print(f\"No image files found for condition {condition}, subcondition {subcondition}.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate mean intensity for samples\n",
    "            with mp.Pool(mp.cpu_count()) as pool:\n",
    "                mean_intensity_list = list(tqdm(pool.imap(calculate_mean_intensity, paths), total=len(paths), desc=f\"Calculating intensities for {condition} - {subcondition}\"))\n",
    "\n",
    "            # Calculate protein concentrations in ng/ul\n",
    "            protein_concentration_list = [calculate_protein_concentration(intensity, intercept, slope) for intensity in mean_intensity_list]\n",
    "\n",
    "            # Convert to nM\n",
    "            protein_concentration_nM_list = [calculate_protein_concentration_nM(conc_ng_ul, mw_kda) for conc_ng_ul in protein_concentration_list]\n",
    "\n",
    "            # Normalize intensities and concentrations\n",
    "            min_intensity = min(mean_intensity_list)\n",
    "            mean_intensity_list = np.array(mean_intensity_list) - min_intensity\n",
    "            protein_concentration_list = np.array(protein_concentration_list) - min(protein_concentration_list)\n",
    "            protein_concentration_nM_list = np.array(protein_concentration_nM_list) - min(protein_concentration_nM_list)\n",
    "\n",
    "            # Time values\n",
    "            time_values_s = np.arange(len(mean_intensity_list)) * time_interval_s\n",
    "            time_values_s, time_values_min, time_values_h = convert_time_units(time_values_s)\n",
    "            \n",
    "            df = pd.DataFrame({\n",
    "                \"Condition\": condition,\n",
    "                \"Subcondition\": subcondition,\n",
    "                \"Time_s\": time_values_s,\n",
    "                \"Time_min\": time_values_min,\n",
    "                \"Time_h\": time_values_h,\n",
    "                \"Mean Intensity\": mean_intensity_list,\n",
    "                \"Protein Concentration_ng_ul\": protein_concentration_list,\n",
    "                \"Protein Concentration_nM\": protein_concentration_nM_list\n",
    "            })\n",
    "\n",
    "            # Calculate number of protein molecules\n",
    "            protein_mass_list = df[\"Protein Concentration_ng_ul\"] * droplet_volume\n",
    "            df[\"Number of Protein Molecules\"] = [calculate_number_of_protein_molecules(mass, mw_kda) for mass in protein_mass_list]\n",
    "\n",
    "            # Calculate rate of change of protein molecules\n",
    "            t_vals = np.linspace(0, (len(df) - 1) * time_interval_s, len(df))\n",
    "            dp_dt = gaussian_filter1d(np.gradient(df[\"Number of Protein Molecules\"], t_vals), sigma=2)\n",
    "            df[\"Rate of Change of Number of Protein Molecules (PM/s)\"] = dp_dt\n",
    "\n",
    "            # Append the data for this condition and subcondition to the list\n",
    "            all_data.append(df)\n",
    "\n",
    "    # Combine all data into a single DataFrame\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Set the output directory within the data path\n",
    "    output_dir = os.path.join(data_path, \"output_data\")\n",
    "    ensure_output_dir(output_dir)\n",
    "\n",
    "    # Save combined results to CSV\n",
    "    combined_csv_path = os.path.join(output_dir, \"combined_experiment.csv\")\n",
    "    combined_df.to_csv(combined_csv_path, index=False)\n",
    "\n",
    "    # Plotting\n",
    "    plot_results(combined_df, output_dir, sample_concentration_values, mean_intensity_calibration, slope, intercept)\n",
    "\n",
    "    return combined_csv_path\n",
    "\n",
    "def plot_results(df, output_dir, sample_concentration_values, mean_intensity_calibration, slope, intercept):\n",
    "    \"\"\"Generate plots based on the processed data.\"\"\"\n",
    "    # Create subdirectories for plots\n",
    "    single_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"single_plots\")\n",
    "    combined_plot_dir = os.path.join(output_dir, \"experiment_plots\", \"combined_plots\")\n",
    "    ensure_output_dir(single_plot_dir)\n",
    "    ensure_output_dir(combined_plot_dir)\n",
    "\n",
    "    # Plot calibration curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sample_concentration_values, mean_intensity_calibration, 'o', label='Data points', linewidth=0.75, markersize=5)\n",
    "    plt.plot(sample_concentration_values, slope * np.array(sample_concentration_values) + intercept, 'r-', label=f'Fit: y = {slope:.2f}x + {intercept:.2f}', linewidth=0.75)\n",
    "    plt.title('Mean Intensity vs Protein Concentration')\n",
    "    plt.xlabel('Protein Concentration (ug/ml)')\n",
    "    plt.ylabel('Mean Intensity')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(single_plot_dir, 'mean_intensity_vs_protein_concentration.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot calibration curve (log scale)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sample_concentration_values, mean_intensity_calibration, 'o', label='Data points', linewidth=0.75, markersize=5)\n",
    "    plt.plot(sample_concentration_values, slope * np.array(sample_concentration_values) + intercept, 'r-', label=f'Fit: y = {slope:.2f}x + {intercept:.2f}', linewidth=0.75)\n",
    "    plt.title('Mean Intensity vs Protein Concentration (Log Scale)')\n",
    "    plt.xlabel('Protein Concentration (ug/ml)')\n",
    "    plt.ylabel('Mean Intensity')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(single_plot_dir, 'mean_intensity_vs_protein_concentration_log.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Time units and concentration units to plot\n",
    "    time_units = [(\"Time_s\", \"Time_s\"), (\"Time_min\", \"Time_min\"), (\"Time_h\", \"Time_h\")]\n",
    "    protein_concentration_units = [\n",
    "        (\"Protein Concentration_ng_ul\", \"Protein Concentration_ng_ul\"),\n",
    "        (\"Protein Concentration_nM\", \"Protein Concentration_nM\"),\n",
    "        (\"Number of Protein Molecules\", \"Number of Protein Molecules\")\n",
    "    ]\n",
    "\n",
    "    # Plot protein concentration over time for each time and concentration unit\n",
    "    for time_unit, time_label in time_units:\n",
    "        for conc_unit, conc_label in protein_concentration_units:\n",
    "            # Individual plots for each condition and subcondition\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "                    plt.title(f'{conc_label} vs {time_label} for {condition} {subcondition}')\n",
    "                    plt.xlabel(time_label)\n",
    "                    plt.ylabel(conc_label)\n",
    "                    plt.legend()\n",
    "                    plt.grid(True)\n",
    "                    plt.savefig(os.path.join(single_plot_dir, f'{condition}_{subcondition}_{conc_label}_vs_{time_label}.png'))\n",
    "                    plt.close()\n",
    "\n",
    "            # Combined plots for all conditions and subconditions\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Combined {conc_label} vs {time_label} for all conditions')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(combined_plot_dir, f'combined_{conc_label}_vs_{time_label}.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # Combined plots for all conditions and subconditions (log scale)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for condition in df[\"Condition\"].unique():\n",
    "                for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "                    condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "                    plt.plot(condition_data[time_unit], condition_data[conc_unit], 'o-', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "            plt.title(f'Combined {conc_label} vs {time_label} for all conditions (Log Scale)')\n",
    "            plt.xlabel(time_label)\n",
    "            plt.ylabel(conc_label)\n",
    "            plt.yscale('log')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(combined_plot_dir, f'combined_{conc_label}_vs_{time_label}_log.png'))\n",
    "            plt.close()\n",
    "\n",
    "    # Plot rate of change of protein molecules\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for condition in df[\"Condition\"].unique():\n",
    "        for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "            condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "            plt.plot(condition_data[\"Time_h\"], condition_data[\"Rate of Change of Number of Protein Molecules (PM/s)\"], 'o', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "    plt.title('Rate of Change of Number of Protein Molecules vs Time_h')\n",
    "    plt.xlabel('Time_h')\n",
    "    plt.ylabel('Rate of Change (PM/s)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(combined_plot_dir, 'rate_of_change_of_protein_molecules_vs_time_h.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot rate of change of protein molecules (log scale)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for condition in df[\"Condition\"].unique():\n",
    "        for subcondition in df[df[\"Condition\"] == condition][\"Subcondition\"].unique():\n",
    "            condition_data = df[(df[\"Condition\"] == condition) & (df[\"Subcondition\"] == subcondition)]\n",
    "            plt.plot(condition_data[\"Time_h\"], condition_data[\"Rate of Change of Number of Protein Molecules (PM/s)\"], 'o', label=f'{condition} {subcondition}', linewidth=0.75, markersize=5)\n",
    "    plt.title('Rate of Change of Number of Protein Molecules vs Time_h (Log Scale)')\n",
    "    plt.xlabel('Time_h')\n",
    "    plt.ylabel('Rate of Change (PM/s)')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(combined_plot_dir, 'rate_of_change_of_protein_molecules_vs_time_h_log.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Example usage\n",
    "\n",
    "mw_kda_list = [100] * len(conditions)\n",
    "droplet_volume_list = [2] * len(conditions)\n",
    "time_interval_list = [120] * len(conditions)\n",
    "\n",
    "# Quantify tiff files\n",
    "quantify_tiffiles(data_path, conditions, subconditions, calibration_curve_paths, mw_kda_list, droplet_volume_list, time_interval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import logging\n",
    "\n",
    "# Ensure logging captures warnings and errors\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "def calculate_RpD2(R_p, D, k_TX):\n",
    "    \"\"\"Calculate RpD2 based on the provided parameters.\"\"\"\n",
    "    discriminant = (R_p + D + k_TX)**2 - 4 * R_p * D\n",
    "    return 1e-6 if discriminant < 0 else 0.5 * (R_p + D + k_TX - np.sqrt(discriminant))\n",
    "\n",
    "def dPdt(T, P, Q, S, tau_0, tau_f, tau_m, K_p):\n",
    "    \"\"\"Differential equation for protein concentration.\"\"\"\n",
    "    if T > tau_0 + tau_f:\n",
    "        return Q * (1 - np.exp(-(T - tau_0 - tau_f) / tau_m)) - (S * P) / (K_p + P)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def solve_ODE(params, N_p, N_m, D, T):\n",
    "    \"\"\"Solve the ODE for protein concentration.\"\"\"\n",
    "    k_TL, k_TX, R_p, tau_m, K_TL, R, k_deg, X_p, K_p, tau_0, tau_f = params\n",
    "\n",
    "    RpD = calculate_RpD2(R_p, D, k_TX)\n",
    "    Q = (k_TL * k_TX * RpD * tau_m) / (N_p * (1 + K_TL / R) * N_m)\n",
    "    S = k_deg * X_p\n",
    "\n",
    "    P_initial = 0\n",
    "    solvers = [\"LSODA\", \"BDF\", \"RK45\", \"Radau\", \"DOP853\", \"RK23\"]\n",
    "    for solver in solvers:\n",
    "        try:\n",
    "            p = solve_ivp(dPdt, [T[0], T[-1]], [P_initial], t_eval=T, args=(Q, S, tau_0, tau_f, tau_m, K_p), method=solver, rtol=1e-6, atol=1e-8)\n",
    "            if p.status == 0:\n",
    "                return p.y[0]\n",
    "        except (ValueError, RuntimeError) as e:\n",
    "            logging.warning(f\"Solver {solver} failed with error: {e}\")\n",
    "            continue\n",
    "    raise RuntimeError(\"All ODE solvers failed\")\n",
    "\n",
    "def objective_function(params, N_p, N_m, D, protein):\n",
    "    \"\"\"Objective function for optimization.\"\"\"\n",
    "    T = np.linspace(0, 5000, len(protein))\n",
    "    try:\n",
    "        pModel = solve_ODE(params, N_p, N_m, D, T)\n",
    "    except RuntimeError as e:\n",
    "        logging.error(f\"ODE solver failed with error: {e}\")\n",
    "        return np.inf\n",
    "    if pModel.shape != protein.shape:\n",
    "        pModel = np.resize(pModel, protein.shape)\n",
    "    return np.sum((protein - pModel)**2)\n",
    "\n",
    "def optimize_parameters(initial_guesses, N_p, N_m, D, protein):\n",
    "    \"\"\"Optimize parameters using the L-BFGS-B method.\"\"\"\n",
    "    bounds = [(0, guess * 100) for guess in initial_guesses]\n",
    "    result = minimize(objective_function, initial_guesses, args=(N_p, N_m, D, protein), method='L-BFGS-B', bounds=bounds)\n",
    "    return result.x\n",
    "\n",
    "def bootstrap_helper(args):\n",
    "    \"\"\"Helper function for multiprocessing bootstrapping.\"\"\"\n",
    "    initial_guesses, N_p, N_m, D, protein, distribution, seed = args\n",
    "    np.random.seed(seed)\n",
    "    bounds = [(1E-9, guess * 500) for guess in initial_guesses]\n",
    "\n",
    "    if distribution == \"uniform\":\n",
    "        random_initial_guesses = [np.random.uniform(low, high) for low, high in bounds]\n",
    "    elif distribution == \"normal\":\n",
    "        random_initial_guesses = [np.clip(norm.rvs(loc=guess, scale=guess * 0.3), low, high) for guess, (low, high) in zip(initial_guesses, bounds)]\n",
    "\n",
    "    optimized_params = optimize_parameters(random_initial_guesses, N_p, N_m, D, protein)\n",
    "    sse = objective_function(optimized_params, N_p, N_m, D, protein)\n",
    "    return optimized_params.tolist() + [sse]\n",
    "\n",
    "def bootstrap_optimizations(initial_guesses, N_p, N_m, D, protein, num_iterations=10, distribution=\"uniform\", save_path=None):\n",
    "    \"\"\"Perform bootstrapping optimizations using all available cores.\"\"\"\n",
    "    args_list = [(initial_guesses, N_p, N_m, D, protein, distribution, seed) for seed in range(num_iterations)]\n",
    "\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(bootstrap_helper, args_list), total=num_iterations, desc=\"Bootstrap Optimizations\"))\n",
    "\n",
    "    # Convert results to DataFrame and sort\n",
    "    columns = [\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\", \"SSE\"]\n",
    "    bootstrap_df = pd.DataFrame(results, columns=columns)\n",
    "    bootstrap_df[\"N_p\"] = N_p\n",
    "    bootstrap_df[\"N_m\"] = N_m\n",
    "    bootstrap_df[\"D\"] = D\n",
    "    bootstrap_df_sorted = bootstrap_df.sort_values(by=\"SSE\")\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    bootstrap_df_sorted = bootstrap_df_sorted.drop_duplicates()\n",
    "\n",
    "    # Save ranked DataFrame if save_path is provided\n",
    "    if save_path:\n",
    "        bootstrap_df_sorted.to_csv(save_path, index=False)\n",
    "\n",
    "    return bootstrap_df_sorted\n",
    "\n",
    "def ensure_output_dir(output_dir):\n",
    "    \"\"\"Ensure that the output directory exists.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "def run_bootstrap_analysis(data_path, conditions, subconditions, initial_guesses_list, N_p_list, N_m_list, D_list, num_iterations=10, distribution=\"uniform\"):\n",
    "    \"\"\"Run bootstrapping analysis for each condition and subcondition.\"\"\"\n",
    "    combined_csv_path = os.path.join(data_path, \"output_data\", \"combined_experiment.csv\")\n",
    "    combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        initial_guesses = initial_guesses_list[idx]\n",
    "        N_p = N_p_list[idx]\n",
    "        N_m = N_m_list[idx]\n",
    "        D = D_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            condition_data = combined_df[(combined_df[\"Condition\"] == condition) & (combined_df[\"Subcondition\"] == subcondition)]\n",
    "            protein = condition_data[\"Protein Concentration_nM\"].values\n",
    "\n",
    "            output_dir = os.path.join(data_path, \"output_data\", f'{condition}_{subcondition}')\n",
    "            ensure_output_dir(output_dir)\n",
    "            save_path = os.path.join(output_dir, 'bootstrap_results.csv')\n",
    "\n",
    "            bootstrap_df_sorted = bootstrap_optimizations(initial_guesses, N_p, N_m, D, protein, num_iterations, distribution, save_path)\n",
    "            logging.info(f\"Bootstrap results saved for condition: {condition}, subcondition: {subcondition}\")\n",
    "\n",
    "def save_theoretical_curves(bootstrap_df_sorted, protein, N_p, N_m, D, output_dir, discard_repeats=True):\n",
    "    \"\"\"Save theoretical curves.\"\"\"\n",
    "    if discard_repeats:\n",
    "        bootstrap_df_sorted = bootstrap_df_sorted.drop_duplicates(subset=[\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"])\n",
    "\n",
    "    ensure_output_dir(output_dir)\n",
    "\n",
    "    all_params = bootstrap_df_sorted[[\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"]].values\n",
    "    T = np.linspace(0, 5000, len(protein))\n",
    "\n",
    "    all_params = all_params[:int(0.1 * len(all_params))]\n",
    "\n",
    "    for rank, params in enumerate(all_params, start=1):\n",
    "        theoretical_curve = solve_ODE(params, N_p, N_m, D, T)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(T, protein, label='Experimental Curve', linestyle='--', color='orange')\n",
    "        plt.plot(T, theoretical_curve, label='Theoretical Curve', color='blue')\n",
    "        plt.title(f'Protein Concentration vs. Time (Rank {rank})')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Protein Concentration (nM)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.ylim(0, 1000)\n",
    "\n",
    "        param_legend = '\\n'.join([f\"{name}={value:.2f}\" for name, value in zip(\n",
    "            [\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"], params)])\n",
    "        plt.annotate(param_legend, xy=(0.05, 0.95), xycoords='axes fraction', fontsize=10, verticalalignment='top')\n",
    "\n",
    "        plt.savefig(os.path.join(output_dir, f'theoretical_curve_rank_{rank}.png'))\n",
    "        plt.close()\n",
    "\n",
    "def plot_experimental_vs_theoretical(bootstrap_df_sorted, protein, N_p, N_m, D, output_dir, discard_repeats=True):\n",
    "    \"\"\"Plot experimental vs. theoretical protein concentration curves.\"\"\"\n",
    "    if discard_repeats:\n",
    "        bootstrap_df_sorted = bootstrap_df_sorted.drop_duplicates(subset=[\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"])\n",
    "\n",
    "    ensure_output_dir(output_dir)\n",
    "\n",
    "    all_params = bootstrap_df_sorted[[\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"]].values\n",
    "    T = np.linspace(0, 5000, len(protein))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(T, protein, label='Experimental Curve', linestyle='--', color='orange')\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(all_params)))\n",
    "    for rank, (params, color) in enumerate(zip(all_params, colors), start=1):\n",
    "        theoretical_curve = solve_ODE(params, N_p, N_m, D, T)\n",
    "        plt.plot(T, theoretical_curve, alpha=0.6, color=color, label=f'Rank {rank}')\n",
    "\n",
    "    plt.title('Protein Concentration vs. Time')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Protein Concentration (nM)')\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 1000)\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'experimental_vs_theoretical.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_parameter_spread(bootstrap_df_sorted, output_dir, discard_repeats=True):\n",
    "    \"\"\"Plot the spread of optimized parameters.\"\"\"\n",
    "    if discard_repeats:\n",
    "        bootstrap_df_sorted = bootstrap_df_sorted.drop_duplicates(subset=[\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"])\n",
    "\n",
    "    ensure_output_dir(output_dir)\n",
    "\n",
    "    params = [\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"]\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(20, 15))\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(bootstrap_df_sorted)))\n",
    "\n",
    "    bootstrap_df_sorted = bootstrap_df_sorted.sort_values(by=\"SSE\")\n",
    "\n",
    "    for i, param in enumerate(params):\n",
    "        ax = axs[i // 4, i % 4]\n",
    "        y = bootstrap_df_sorted[param]\n",
    "        x = np.arange(1, len(y) + 1) + np.random.uniform(-0.2, 0.2, size=len(y))\n",
    "        c = [colors[rank] for rank in range(len(bootstrap_df_sorted))]\n",
    "\n",
    "        ax.scatter(x, y, color=c, alpha=0.5, s=50)\n",
    "        ax.set_xticks(range(1, len(bootstrap_df_sorted) + 1))\n",
    "        ax.set_xticklabels(range(1, len(bootstrap_df_sorted) + 1))\n",
    "        ax.set_xlabel('Rank')\n",
    "        ax.set_ylabel(param)\n",
    "        ax.set_title(param)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'parameter_spread.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_parameter_combinations(bootstrap_df_sorted, output_dir, discard_repeats=True):\n",
    "    \"\"\"Plot combinations of parameters.\"\"\"\n",
    "    if discard_repeats:\n",
    "        bootstrap_df_sorted = bootstrap_df_sorted.drop_duplicates(subset=[\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"])\n",
    "\n",
    "    ensure_output_dir(output_dir)\n",
    "\n",
    "    params = [\"k_TL\", \"k_TX\", \"R_p\", \"tau_m\", \"K_TL\", \"R\", \"k_deg\", \"X_p\", \"K_p\", \"tau_0\", \"tau_f\"]\n",
    "    combinations = list(itertools.combinations(params, 2))\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(bootstrap_df_sorted)))\n",
    "\n",
    "    bootstrap_df_sorted = bootstrap_df_sorted.sort_values(by=\"SSE\")\n",
    "\n",
    "    for i, (param1, param2) in enumerate(combinations):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        color = colors[i % len(colors)]\n",
    "        plt.scatter(bootstrap_df_sorted[param1], bootstrap_df_sorted[param2], alpha=0.6, color=color)\n",
    "        plt.xlabel(param1)\n",
    "        plt.ylabel(param2)\n",
    "        plt.title(f'{param1} vs {param2}')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_dir, f'{param1}_vs_{param2}.png'))\n",
    "        plt.close()\n",
    "\n",
    "def run_all_plots(data_path, conditions, subconditions, initial_guesses_list, N_p_list, N_m_list, D_list, discard_repeats=True):\n",
    "    \"\"\"Run all plotting functions for each condition and subcondition.\"\"\"\n",
    "    combined_csv_path = os.path.join(data_path, \"output_data\", \"combined_experiment.csv\")\n",
    "    combined_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "    for idx, condition in enumerate(conditions):\n",
    "        initial_guesses = initial_guesses_list[idx]\n",
    "        N_p = N_p_list[idx]\n",
    "        N_m = N_m_list[idx]\n",
    "        D = D_list[idx]\n",
    "\n",
    "        for subcondition in subconditions:\n",
    "            condition_data = combined_df[(combined_df[\"Condition\"] == condition) & (combined_df[\"Subcondition\"] == subcondition)]\n",
    "            protein = condition_data[\"Protein Concentration_nM\"].values\n",
    "\n",
    "            output_dir = os.path.join(data_path, \"output_data\", f'{condition}_{subcondition}')\n",
    "            csv_path = os.path.join(output_dir, 'bootstrap_results.csv')\n",
    "            bootstrap_df_sorted = pd.read_csv(csv_path)\n",
    "\n",
    "            condition_output_dir = os.path.join(output_dir)\n",
    "            ensure_output_dir(condition_output_dir)\n",
    "\n",
    "            theoretical_curves_dir = os.path.join(condition_output_dir, 'theoretical_curves')\n",
    "            experimental_vs_theoretical_dir = os.path.join(condition_output_dir, 'experimental_vs_theoretical')\n",
    "            parameter_spread_dir = os.path.join(condition_output_dir, 'parameter_spread')\n",
    "            parameter_combinations_dir = os.path.join(condition_output_dir, 'parameter_combinations')\n",
    "\n",
    "            save_theoretical_curves(bootstrap_df_sorted, protein, N_p, N_m, D, theoretical_curves_dir, discard_repeats)\n",
    "            plot_experimental_vs_theoretical(bootstrap_df_sorted, protein, N_p, N_m, D, experimental_vs_theoretical_dir, discard_repeats)\n",
    "            plot_parameter_spread(bootstrap_df_sorted, parameter_spread_dir, discard_repeats)\n",
    "            plot_parameter_combinations(bootstrap_df_sorted, parameter_combinations_dir, discard_repeats)\n",
    "\n",
    "# Initial guesses for bootstrap optimization\n",
    "initial_guesses_list = [\n",
    "    [10, 1, 30, 720, 5, 190, 0.01, 9, 4, 0, 300]\n",
    "] * len(conditions)\n",
    "\n",
    "N_p_list = [401] * len(conditions)\n",
    "N_m_list = [2097] * len(conditions)\n",
    "D_list = [100] * len(conditions)\n",
    "\n",
    "# Run bootstrap analysis\n",
    "run_bootstrap_analysis(\n",
    "    data_path, conditions, subconditions, initial_guesses_list,\n",
    "    N_p_list, N_m_list, D_list, num_iterations=30, distribution=\"normal\"\n",
    ")\n",
    "\n",
    "# Run all plots\n",
    "run_all_plots(\n",
    "    data_path, conditions, subconditions, initial_guesses_list,\n",
    "    N_p_list, N_m_list, D_list, discard_repeats=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
