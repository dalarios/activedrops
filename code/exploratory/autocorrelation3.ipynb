{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:** Calculate and visualize the velocity autocorrelation of fluid flow from PIV (Particle Image Velocimetry) data. The data is in a series of `.txt` files, with each file corresponding to a frame in time. \n",
    "\n",
    "**Procedure:**\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "    - Load the `.txt` file.\n",
    "    - Convert the position and velocity data from meters and meters/second to micrometers and micrometers/second, respectively.\n",
    "    - Retain only the converted columns: `x [um]`, `y [um]`, `u [um/s]`, and `v [um/s]`.\n",
    "\n",
    "2. **Velocity Autocorrelation Calculation**:\n",
    "    - For each frame, compute the velocity autocorrelation. There are two methods to do this:\n",
    "        1. Using the `correlate2d` method from `scipy.signal`.\n",
    "        2. Using Fourier transformations.\n",
    "    - Normalize the velocities and handle any NaN values by replacing them with zeros.\n",
    "    - Extract the radial form of the 2D autocorrelation.\n",
    "\n",
    "3. **Exponential Fit**:\n",
    "    - Fit the radial velocity autocorrelation to an exponential function.\n",
    "    - Extract the correlation length, \\( \\lambda \\), from the fit.\n",
    "    - Plot the original data (radial autocorrelation) and the exponential fit on the same graph for comparison.\n",
    "\n",
    "4. **Visualization**:\n",
    "    - Plot the 2D autocorrelation for visualization.\n",
    "    - Use a color map (e.g., 'viridis') for better visualization.\n",
    "    - Add necessary labels, titles, and grids for clarity.\n",
    "\n",
    "**Expected Results**: \n",
    "- A series of plots showing the velocity autocorrelation and its exponential fit for each frame.\n",
    "- A visualization of the 2D autocorrelation for each frame.\n",
    "- The correlation length, \\( \\lambda \\), extracted from the fit.\n",
    "\n",
    "**Note**: The procedures provided were based on a previous analysis. Ensure that the data structure, NaN handling, and any other specifics match the current dataset for accurate results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../activedrops')\n",
    "import autocorrelation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import correlate2d\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load our data and convert everything to microns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x [um]</th>\n",
       "      <th>y [um]</th>\n",
       "      <th>u [um/s]</th>\n",
       "      <th>v [um/s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.287672</td>\n",
       "      <td>23.287672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.287672</td>\n",
       "      <td>45.205481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.287672</td>\n",
       "      <td>67.123285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.287672</td>\n",
       "      <td>89.041096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.287672</td>\n",
       "      <td>110.958907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16124</th>\n",
       "      <td>2784.931567</td>\n",
       "      <td>2697.260352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16125</th>\n",
       "      <td>2784.931567</td>\n",
       "      <td>2719.178097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16126</th>\n",
       "      <td>2784.931567</td>\n",
       "      <td>2741.095843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16127</th>\n",
       "      <td>2784.931567</td>\n",
       "      <td>2763.013588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16128</th>\n",
       "      <td>2784.931567</td>\n",
       "      <td>2784.931567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16129 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x [um]       y [um]  u [um/s]  v [um/s]\n",
       "0        23.287672    23.287672       NaN       NaN\n",
       "1        23.287672    45.205481       NaN       NaN\n",
       "2        23.287672    67.123285       NaN       NaN\n",
       "3        23.287672    89.041096       NaN       NaN\n",
       "4        23.287672   110.958907       NaN       NaN\n",
       "...            ...          ...       ...       ...\n",
       "16124  2784.931567  2697.260352       NaN       NaN\n",
       "16125  2784.931567  2719.178097       NaN       NaN\n",
       "16126  2784.931567  2741.095843       NaN       NaN\n",
       "16127  2784.931567  2763.013588       NaN       NaN\n",
       "16128  2784.931567  2784.931567       NaN       NaN\n",
       "\n",
       "[16129 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = \"../../data/k401bio-250nM-piv/PIVlab_0001.txt\"\n",
    "\n",
    "# Load the data using the updated function\n",
    "data_0001 = autocorrelation.load_and_convert_data(link)\n",
    "\n",
    "data_0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity_autocorrelation_fourier(data):\n",
    "    \"\"\"\n",
    "    Compute the spatial autocorrelation of the velocity field using Fourier transforms.\n",
    "    \"\"\"\n",
    "    # Extracting the velocities\n",
    "    u = data.pivot(index='y [um]', columns='x [um]', values='u [um/s]').values\n",
    "    v = data.pivot(index='y [um]', columns='x [um]', values='v [um/s]').values\n",
    "\n",
    "    # Handle NaN values: replacing them with zero\n",
    "    u[np.isnan(u)] = 0\n",
    "    v[np.isnan(v)] = 0\n",
    "\n",
    "    # Normalizing the velocities\n",
    "    u_norm = u - np.mean(u)\n",
    "    v_norm = v - np.mean(v)\n",
    "\n",
    "    # Fourier transform of the normalized velocities\n",
    "    F_u_norm = np.fft.fft2(u_norm)\n",
    "    F_v_norm = np.fft.fft2(v_norm)\n",
    "    \n",
    "    # Power spectrum\n",
    "    power_spectrum_u = np.abs(F_u_norm)**2\n",
    "    power_spectrum_v = np.abs(F_v_norm)**2\n",
    "    \n",
    "    # Inverse Fourier transform of the power spectrum gives the autocorrelation\n",
    "    R_u = np.fft.ifft2(power_spectrum_u).real\n",
    "    R_v = np.fft.ifft2(power_spectrum_v).real\n",
    "    \n",
    "    # Shift the result to have zero at the center\n",
    "    R_u = np.fft.fftshift(R_u)\n",
    "    R_v = np.fft.fftshift(R_v)\n",
    "    \n",
    "    return R_u, R_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 2D velocity autocorrelation using Fourier method\n",
    "R_u_fourier, R_v_fourier = compute_velocity_autocorrelation_fourier(data_0001)\n",
    "R_uv_fourier = np.dot(R_u_fourier,R_v_fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(R_uv_fourier, cmap='viridis', origin='lower', extent=[-R_u_fourier.shape[1]//2, R_u_fourier.shape[1]//2, -R_u_fourier.shape[0]//2, R_u_fourier.shape[0]//2])\n",
    "plt.colorbar(label=\"Autocorrelation Value\")\n",
    "plt.title(\"2D Velocity Autocorrelation (Fourier Method) - u Component\")\n",
    "plt.xlabel(\"Spatial Lag in x-direction (microns)\")\n",
    "plt.ylabel(\"Spatial Lag in y-direction (microns)\")\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_radial_velocity_product_correlation(R):\n",
    "    \"\"\"\n",
    "    Extract the radial autocorrelation from the 2D autocorrelation.\n",
    "    \"\"\"\n",
    "    y, x = np.indices(R.shape)\n",
    "    r = np.sqrt((x - R.shape[1]//2)**2 + (y - R.shape[0]//2)**2).astype(int)\n",
    "    radial_mean = np.bincount(r.ravel(), R.ravel()) / np.bincount(r.ravel())\n",
    "    \n",
    "    return radial_mean\n",
    "\n",
    "def exponential_fit(r, A, B, C):\n",
    "    \"\"\"\n",
    "    Exponential function for fitting the autocorrelation.\n",
    "    \"\"\"\n",
    "    return A * np.exp(-r / B) + C\n",
    "\n",
    "def fit_and_extract_lambda(distances, radial_velocity):\n",
    "    \"\"\"\n",
    "    Fit the radial velocity autocorrelation to the exponential function and extract lambda.\n",
    "    \"\"\"\n",
    "    # Fitting the radial autocorrelation to the exponential function\n",
    "    popt, _ = curve_fit(exponential_fit, distances, radial_velocity, p0=[1, 100, 0])\n",
    "    \n",
    "    # Extracting the correlation length lambda from the fit parameters\n",
    "    A, B, C = popt\n",
    "    lambda_val = -B * np.log((0.3 - C) / A)\n",
    "    \n",
    "    return lambda_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the radial autocorrelation\n",
    "radial_autocorr_fourier = extract_radial_velocity_product_correlation(R_u_fourier)\n",
    "\n",
    "# Adjusting the distances array to match the size of the radial_autocorr_fourier\n",
    "distances_fourier = np.arange(len(radial_autocorr_fourier))\n",
    "\n",
    "# Fit the radial autocorrelation to the exponential function to extract the correlation length\n",
    "correlation_length_fourier = fit_and_extract_lambda(distances_fourier, radial_autocorr_fourier)\n",
    "\n",
    "correlation_length_fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exponential_fit(distances, radial_velocity):\n",
    "    \"\"\"\n",
    "    Fit the radial velocity autocorrelation to the exponential function and plot the fit along with the original data.\n",
    "    \"\"\"\n",
    "    # Fitting the radial autocorrelation to the exponential function\n",
    "    popt, _ = curve_fit(exponential_fit, distances, radial_velocity, p0=[1, 100, 0])\n",
    "    \n",
    "    # Generating the exponential curve using the fitted parameters\n",
    "    fitted_curve = exponential_fit(distances, *popt)\n",
    "    \n",
    "    # Plotting\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(distances, radial_velocity, 'b-', label=\"Original Data\")\n",
    "    plt.plot(distances, fitted_curve, 'r--', label=\"Exponential Fit\")\n",
    "    plt.xlabel(\"Distance (in microns)\")\n",
    "    plt.ylabel(\"Velocity Autocorrelation\")\n",
    "    plt.title(\"Velocity Autocorrelation and Exponential Fit\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract radial form of the velocity autocorrelation for both frames\n",
    "radial_velocity_0001 = extract_radial_velocity_product_correlation(R_velocity_0001)\n",
    "\n",
    "# Plotting the exponential fit for the radial_velocity_0001 data\n",
    "distances = np.arange(len(radial_velocity_0001))\n",
    "plot_exponential_fit(distances, radial_velocity_0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
