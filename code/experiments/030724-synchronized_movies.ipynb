{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file name.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(file_path)\n",
    "    tokens = filename.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Filename {filename} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_videos(videos_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple video files based on a common time axis.\n",
    "    \n",
    "    Instead of specifying an absolute time_step, the function computes the base time step \n",
    "    (i.e. the minimum effective frame duration among the videos) and then multiplies it \n",
    "    by the provided time_multiplier.\n",
    "    \n",
    "    IMPORTANT: To ensure the movies are never cut short, the function uses the maximum total\n",
    "    effective time among the videos. That way the output covers the entire duration of all movies;\n",
    "    for any video that ends before the others, its last frame is repeated.\n",
    "    \n",
    "    Parameters:\n",
    "        videos_dict (dict): Keys are video file paths, values are effective frame durations (in seconds)\n",
    "                            for each video.\n",
    "        time_multiplier (float): Multiplier to the base time step (min of frame durations). \n",
    "                                 For maximum resolution, use 1.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout for the output video.\n",
    "        fps_output (float, optional): Output video playback frames per second. Defaults to 30.0.\n",
    "        output_file_path (str, optional): A file path whose directory is used for saving the output video.\n",
    "                                          The final file name will include the protein names.\n",
    "        \n",
    "    Returns:\n",
    "        None. The output video is saved to a file in the specified directory.\n",
    "        Also prints the total playback duration (in seconds) of the output grid video.\n",
    "    \"\"\"\n",
    "    # Convert videos_dict keys and values to lists\n",
    "    file_paths = list(videos_dict.keys())\n",
    "    frame_durations = list(videos_dict.values())\n",
    "    \n",
    "    n_videos = len(file_paths)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in file_paths]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name using the output file path's directory.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Open all videos to get info.\n",
    "    caps = [cv2.VideoCapture(fp) for fp in file_paths]\n",
    "    \n",
    "    # Calculate each video's total time.\n",
    "    # --- NEVER CUT SHORT: Use the maximum total time so that the output covers the full duration of all movies.\n",
    "    total_times = []\n",
    "    num_frames_list = []  # store total frames for each video\n",
    "    for cap, fd in zip(caps, frame_durations):\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        num_frames_list.append(num_frames)\n",
    "        total_times.append(num_frames * fd)\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute base time step as the minimum effective frame duration among videos.\n",
    "    base_time_step = min(frame_durations)\n",
    "    # Final time step is base multiplied by the given multiplier.\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine the number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration of the output video.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    \n",
    "    # Read the first frame from each video to get dimensions.\n",
    "    dimensions = []\n",
    "    for cap in caps:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            raise ValueError(\"Failed to read the first frame from one or more videos.\")\n",
    "        h, w = frame.shape[:2]\n",
    "        dimensions.append((h, w))\n",
    "    \n",
    "    # Define a common cell size using the maximum height and width among all videos.\n",
    "    cell_height = max(h for h, w in dimensions)\n",
    "    cell_width  = max(w for h, w in dimensions)\n",
    "    \n",
    "    # Calculate output video dimensions based on grid shape.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width  = grid_shape[1] * cell_width\n",
    "    \n",
    "    # Define the codec and create the VideoWriter object for the output video.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each video.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        for idx, (cap, fd) in enumerate(zip(caps, frame_durations)):\n",
    "            frame_idx = int(current_time / fd)\n",
    "            if frame_idx >= num_frames_list[idx]:\n",
    "                frame_idx = num_frames_list[idx] - 1\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                frame = np.zeros((dimensions[idx][0], dimensions[idx][1], 3), dtype=np.uint8)\n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    for cap in caps:\n",
    "        cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "# Example usage:\n",
    "output_file_path = \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/all/movies/\"\n",
    "\n",
    "\n",
    "videos = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_cy5_60fps_1008frames.avi\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_cy5_60fps_481frames.avi\": 300,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_cy5_60fps_481frames.avi\": 300,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_cy5_60fps_507frames.avi\": 32,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_cy5_60fps_675frames.avi\": 18,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# For maximum temporal resolution, use a multiplier of 1.\n",
    "# Increase the multiplier to reduce the number of output frames.\n",
    "time_multiplier = 50\n",
    "grid_shape = (1, 4)\n",
    "\n",
    "synchronize_videos(videos, time_multiplier, grid_shape, channel=\"cy5\", fps_output=30, output_file_path=output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "        \n",
    "        # Print first few frames to verify sorting\n",
    "        print(f\"Pattern: {pattern}\")\n",
    "        print(f\"  Total frames: {len(frame_files)}\")\n",
    "        print(f\"  First 5 frames: {[os.path.basename(f) for f in frame_files[:5]]}\")\n",
    "        print(f\"  Last 5 frames: {[os.path.basename(f) for f in frame_files[-5:]]}\")\n",
    "        print()\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    print(f\"Base time step: {base_time_step}s, Final time step: {time_step}s\")\n",
    "    print(f\"Total sync time: {total_time_sync/3600:.2f} hours\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    print(f\"Individual frame dimensions: {cell_width}x{cell_height}\")\n",
    "    print(f\"Output grid dimensions: {output_frame_width}x{output_frame_height}\")\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 32,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 18,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 32  # Maximum temporal resolution!\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "        \n",
    "        # Print first few frames to verify sorting\n",
    "        print(f\"Pattern: {pattern}\")\n",
    "        print(f\"  Total frames: {len(frame_files)}\")\n",
    "        print(f\"  First 5 frames: {[os.path.basename(f) for f in frame_files[:5]]}\")\n",
    "        print(f\"  Last 5 frames: {[os.path.basename(f) for f in frame_files[-5:]]}\")\n",
    "        print()\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    print(f\"Base time step: {base_time_step}s, Final time step: {time_step}s\")\n",
    "    print(f\"Total sync time: {total_time_sync/3600:.2f} hours\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    print(f\"Individual frame dimensions: {cell_width}x{cell_height}\")\n",
    "    print(f\"Output grid dimensions: {output_frame_width}x{output_frame_height}\")\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 32,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 18,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 32  # Maximum temporal resolution!\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "        \n",
    "        # Print first few frames to verify sorting\n",
    "        print(f\"Pattern: {pattern}\")\n",
    "        print(f\"  Total frames: {len(frame_files)}\")\n",
    "        print(f\"  First 5 frames: {[os.path.basename(f) for f in frame_files[:5]]}\")\n",
    "        print(f\"  Last 5 frames: {[os.path.basename(f) for f in frame_files[-5:]]}\")\n",
    "        print()\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    print(f\"Base time step: {base_time_step}s, Final time step: {time_step}s\")\n",
    "    print(f\"Total sync time: {total_time_sync/3600:.2f} hours\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    print(f\"Individual frame dimensions: {cell_width}x{cell_height}\")\n",
    "    print(f\"Output grid dimensions: {output_frame_width}x{output_frame_height}\")\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 32,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 18,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 32  # Maximum temporal resolution!\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "        \n",
    "        # Print first few frames to verify sorting\n",
    "        print(f\"Pattern: {pattern}\")\n",
    "        print(f\"  Total frames: {len(frame_files)}\")\n",
    "        print(f\"  First 5 frames: {[os.path.basename(f) for f in frame_files[:5]]}\")\n",
    "        print(f\"  Last 5 frames: {[os.path.basename(f) for f in frame_files[-5:]]}\")\n",
    "        print()\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    print(f\"Base time step: {base_time_step}s, Final time step: {time_step}s\")\n",
    "    print(f\"Total sync time: {total_time_sync/3600:.2f} hours\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    print(f\"Individual frame dimensions: {cell_width}x{cell_height}\")\n",
    "    print(f\"Output grid dimensions: {output_frame_width}x{output_frame_height}\")\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 32,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 18,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 32  # Maximum temporal resolution!\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "        \n",
    "        # Print first few frames to verify sorting\n",
    "        print(f\"Pattern: {pattern}\")\n",
    "        print(f\"  Total frames: {len(frame_files)}\")\n",
    "        print(f\"  First 5 frames: {[os.path.basename(f) for f in frame_files[:5]]}\")\n",
    "        print(f\"  Last 5 frames: {[os.path.basename(f) for f in frame_files[-5:]]}\")\n",
    "        print()\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    print(f\"Base time step: {base_time_step}s, Final time step: {time_step}s\")\n",
    "    print(f\"Total sync time: {total_time_sync/3600:.2f} hours\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    print(f\"Individual frame dimensions: {cell_width}x{cell_height}\")\n",
    "    print(f\"Output grid dimensions: {output_frame_width}x{output_frame_height}\")\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 32,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 18,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 32  # Maximum temporal resolution!\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "videos = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/paper-v2/fig2-assets/k401/K401_cy5-4x-240sint.avi\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/paper-v2/fig2-assets/kif3/Kif3_cy5-3x-9sint.avi\": 9,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/paper-v2/fig2-assets/ThTr/ThTr_cy5-4x-240sint.avi\": 240,\n",
    "\n",
    "}\n",
    "\n",
    "# For maximum temporal resolution, use a multiplier of 1.\n",
    "# Increase the multiplier to reduce the number of output frames.\n",
    "time_multiplier = 24\n",
    "grid_shape = (1, 3)\n",
    "\n",
    "synchronize_videos(videos, time_multiplier, grid_shape, channel=\"cy5\", fps_output=60, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [\"160\", \"80\", \"40\", \"20\", \"10\", \"5\", \"2p5\", \"1p25\"]\n",
    "\n",
    "videos = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/101324-k401-titration-rt/2p5TMB-1ulDNA_/output_data/movies/K401_160nM-RT_Rep1_cy5_120fps_2616frames.avi\": 60,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111024-B-F-titrations-RT/2p5TMB-1ulDNA_/output_data_/movies/B_160nM_Rep1_cy5_60fps_961frames.avi\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/C_160nM_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/110324-D_titration-RT/2p5TMB-1ulDNA_1/output_data_/movies/D_2p5nM_Rep1_cy5_24fps_338frames.avi\": 64,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/E_160nM_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111024-B-F-titrations-RT/2p5TMB-1ulDNA_/output_data_/movies/F_160nM_Rep1_cy5_60fps_961frames.avi\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/G_160nM_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/100624-kif3-titration-RT/2p5ulTMB-1ulDNAXnM_/output_data_/movies/Kif3_5nM_2-RT_Rep1_cy5_120fps_1800frames.avi\": 8,\n",
    "\n",
    "}\n",
    "\n",
    "# For maximum temporal resolution, use a multiplier of 1.\n",
    "# Increase the multiplier to reduce the number of output frames.\n",
    "time_multiplier = 64\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_videos(videos, time_multiplier, grid_shape, channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [\"160\", \"80\", \"40\", \"20\", \"10\", \"5\", \"2p5\", \"1p25\"]\n",
    "\n",
    "videos = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/101324-k401-titration-rt/2p5TMB-1ulDNA_/output_data/movies/K401_160nM-RT_Rep1_cy5_120fps_2616frames.avi\": 60,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/091024-sustainedMotors-RT/2p5TMB-1ulDNA100nM_/output_data/movies/Kif5-RT_Rep1_cy5_120fps_2922frames.avi\": 45,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/030225-AdPa-titrations/2p5ulTMB_1ulDNA_/output_data/movies/AdPa_160nM_Rep1_cy5_120fps_1082frames.avi\": 120, \n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/020124-ThTr-titrations-RT/2p5ulTMB-1ulDNA_/output_data_/movies/ThTr_160nM-RT_Rep1_cy5_60fps_1307frames.avi\": 27*4, \n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021025-BleSto-AcSu2-titrations/2p5ulTMB-1ulDNA_1/output_data_/movies/BleSto_80nM_Rep1_cy5_60fps_921frames.avi\": 100,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021025-BleSto-AcSu2-titrations/2p5ulTMB-1ulDNA_1/output_data_/movies/AcSu2_5nM_Rep1_cy5_60fps_921frames.avi\": 100,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021625-HeAl-titrations-RT/2p5ulTMB-1ulDNA_/output_data/movies/HeAl_5nM-RT_Rep1_cy5_60fps_1000frames.avi\": 24,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/030225-NaGr-titrations/2p5ulTMB_1ulDNA_2/output_data/movies/NaGr_5nM_Rep1_cy5_120fps_2000frames.avi\": 12,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021025-DiPu-titrations/2p5ulTMB-1ulDNA_1/output_data_/movies/DiPu_5nM-RT_Rep1_cy5_60fps_880frames.avi\": 60,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/092224-TiLa_NaGr-RT/2p5ulTMB-1ulDNA100nM_/output_data/movies/TiLa-RT_Rep1_cy5_120fps_1800frames.avi\": 8,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/100624-kif3-titration-RT/2p5ulTMB-1ulDNAXnM_/output_data_/movies/Kif3_5nM_2-RT_Rep1_cy5_120fps_1800frames.avi\": 8,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/negative_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "\n",
    "}\n",
    "\n",
    "# For maximum temporal resolution, use a multiplier of 1.\n",
    "# Increase the multiplier to reduce the number of output frames.\n",
    "time_multiplier = 16\n",
    "grid_shape = (3, 4)\n",
    "\n",
    "synchronize_videos(videos, time_multiplier, grid_shape, channel=\"cy5\", fps_output=60, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [\"160\", \"80\", \"40\", \"20\", \"10\", \"5\", \"2p5\", \"1p25\"]\n",
    "\n",
    "\n",
    "for i in concentrations:\n",
    "\n",
    "    videos = {\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/100624-kif3-titration-RT/2p5ulTMB-1ulDNAXnM_/output_data_/movies/Kif3_{i}nM_1-RT_Rep1_cy5_120fps_1800frames.avi\": 6,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/ubuntu/110324-D_titration-RT/2p5TMB-1ulDNA_1/output_data_/movies/D_{i}nM_Rep1_cy5_24fps_338frames.avi\": 64,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/030225-NaGr-titrations/2p5ulTMB_1ulDNA_2/output_data/movies/NaGr_{i}nM_Rep1_cy5_120fps_2000frames.avi\": 12,\n",
    "        \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021625-HeAl-titrations-RT/2p5ulTMB-1ulDNA_/output_data/movies/HeAl_80nM-RT_Rep1_cy5_60fps_1000frames.avi\": 24,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021025-BleSto-AcSu2-titrations/2p5ulTMB-1ulDNA_1/output_data_/movies/AcSu2_{i}nM_Rep1_cy5_60fps_921frames.avi\": 100,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021025-DiPu-titrations/2p5ulTMB-1ulDNA_1/output_data_/movies/DiPu_{i}nM-RT_Rep1_cy5_60fps_880frames.avi\": 60,\n",
    "    }\n",
    "\n",
    "    # For maximum temporal resolution, use a multiplier of 1.\n",
    "    # Increase the multiplier to reduce the number of output frames.\n",
    "    time_multiplier = 16\n",
    "    grid_shape = (2, 3)\n",
    "\n",
    "    synchronize_videos(videos, time_multiplier, grid_shape, channel=\"cy5\", fps_output=60, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [\"160\", \"80\", \"40\", \"20\", \"10\", \"5\", \"2p5\", \"1p25\"]\n",
    "\n",
    "\n",
    "for i in concentrations:\n",
    "\n",
    "    videos = {\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/101324-k401-titration-rt/2p5TMB-1ulDNA_/output_data_/movies/K401_{i}nM-RT_Rep1_cy5_120fps_2616frames.avi\": 60,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/C_{i}nM_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/G_{i}nM_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/020124-ThTr-titrations-RT/2p5ulTMB-1ulDNA_/output_data_/movies/ThTr_{i}nM-RT_Rep1_cy5_60fps_1307frames.avi\": 27*4,\n",
    "\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/030225-AdPa-titrations/2p5ulTMB_1ulDNA_/output_data/movies/AdPa_{i}nM_Rep1_cy5_120fps_1082frames.avi\": 120,\n",
    "\n",
    "    }\n",
    "\n",
    "    # For maximum temporal resolution, use a multiplier of 1.\n",
    "    # Increase the multiplier to reduce the number of output frames.\n",
    "    time_multiplier = 4\n",
    "    grid_shape = (2, 3)\n",
    "\n",
    "    synchronize_videos(videos, time_multiplier, grid_shape, channel=\"cy5\", fps_output=60, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentrations = [\"160\", \"80\", \"40\", \"20\", \"10\", \"5\", \"2p5\", \"1p25\"]\n",
    "\n",
    "\n",
    "for i in concentrations:\n",
    "\n",
    "    videos = {\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/021025-BleSto-AcSu2-titrations/2p5ulTMB-1ulDNA_1/output_data_/movies/AcSu2_80nM_Rep1_cy5_60fps_921frames.avi\n",
    "        \": 60,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/C_{i}nM_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/111624-C-E-G-RT/2p5ulTMB-0p5MT-1ulDNA_/output_data_/movies/G_{i}nM_Rep1_cy5_60fps_743frames.avi\": 150,\n",
    "        f\"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/020124-ThTr-titrations-RT/2p5ulTMB-1ulDNA_/output_data_/movies/ThTr_{i}nM-RT_Rep1_cy5_60fps_1307frames.avi\": 27*4\n",
    "\n",
    "    }\n",
    "\n",
    "    # For maximum temporal resolution, use a multiplier of 1.\n",
    "    # Increase the multiplier to reduce the number of output frames.\n",
    "    time_multiplier = 4\n",
    "    grid_shape = (1, 4)\n",
    "\n",
    "    synchronize_videos(videos, time_multiplier, grid_shape, channel=\"cy5\", fps_output=60, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "        \n",
    "        # Print first few frames to verify sorting\n",
    "        print(f\"Pattern: {pattern}\")\n",
    "        print(f\"  Total frames: {len(frame_files)}\")\n",
    "        print(f\"  First 5 frames: {[os.path.basename(f) for f in frame_files[:5]]}\")\n",
    "        print(f\"  Last 5 frames: {[os.path.basename(f) for f in frame_files[-5:]]}\")\n",
    "        print()\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    print(f\"Base time step: {base_time_step}s, Final time step: {time_step}s\")\n",
    "    print(f\"Total sync time: {total_time_sync/3600:.2f} hours\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    print(f\"Individual frame dimensions: {cell_width}x{cell_height}\")\n",
    "    print(f\"Output grid dimensions: {output_frame_width}x{output_frame_height}\")\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 32,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 18,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 32  # Maximum temporal resolution!\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "        \n",
    "        # Print first few frames to verify sorting\n",
    "        print(f\"Pattern: {pattern}\")\n",
    "        print(f\"  Total frames: {len(frame_files)}\")\n",
    "        print(f\"  First 5 frames: {[os.path.basename(f) for f in frame_files[:5]]}\")\n",
    "        print(f\"  Last 5 frames: {[os.path.basename(f) for f in frame_files[-5:]]}\")\n",
    "        print()\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    final_output_file = os.path.join(out_dir, f\"{proteins_combined}_{channel}_synced.avi\")\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie will be {playback_duration_sec:.2f} seconds long.\")\n",
    "    print(f\"Base time step: {base_time_step}s, Final time step: {time_step}s\")\n",
    "    print(f\"Total sync time: {total_time_sync/3600:.2f} hours\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    print(f\"Individual frame dimensions: {cell_width}x{cell_height}\")\n",
    "    print(f\"Output grid dimensions: {output_frame_width}x{output_frame_height}\")\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved as: {final_output_file}\")\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 32,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 18,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 32  # Maximum temporal resolution!\n",
    "grid_shape = (2, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie duration: 10.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|| 901/901 [04:10<00:00,  3.60frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to: ../../../../Thomson Lab Dropbox/David Larios/activedrops/main/all/movies/OOB_Rep1-OOO_Rep1_cy5_synced_tm1_fps90.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name, including time_multiplier and fps_output.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    # Format time_multiplier and fps_output for filename (avoid decimal point if possible)\n",
    "    tm_str = f\"{int(time_multiplier)}\" if int(time_multiplier) == time_multiplier else f\"{time_multiplier}\"\n",
    "    fps_str = f\"{int(fps_output)}\" if int(fps_output) == fps_output else f\"{fps_output}\"\n",
    "    final_output_file = os.path.join(\n",
    "        out_dir, \n",
    "        f\"{proteins_combined}_{channel}_synced_tm{tm_str}_fps{fps_str}.avi\"\n",
    "    )\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie duration: {playback_duration_sec:.2f} seconds\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved to: {final_output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 240,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 160,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/BOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 150,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    # \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OBO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 300,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOB_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 16*2,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/paper/figures/fig4-assets/original_tiffs/output_data/movies/OOO_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 9*2,\n",
    "}\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 1  # Maximum temporal resolution!\n",
    "grid_shape = (1, 2)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=90, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie duration: 10.67 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|| 320/320 [02:56<00:00,  1.81frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to: ../../../../Thomson Lab Dropbox/David Larios/activedrops/main/all/movies/K401-BIO + Strep_Rep1-K401-BIO + H2O_Rep1-K401_DNA-negative_Rep1_cy5_synced_tm10_fps30.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_protein_name(file_path):\n",
    "    \"\"\"\n",
    "    Extracts the protein name from the file path.\n",
    "    Assumes the protein name is in the first two underscore-separated tokens,\n",
    "    where the second token may have additional info (e.g. \"-RT\") which is removed.\n",
    "    \"\"\"\n",
    "    # Extract the directory name from the path\n",
    "    dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "    tokens = dir_name.split('_')\n",
    "    if len(tokens) < 2:\n",
    "        raise ValueError(f\"Directory name {dir_name} does not have enough tokens to extract protein name.\")\n",
    "    token1 = tokens[0]\n",
    "    token2 = tokens[1].split('-')[0]\n",
    "    return f\"{token1}_{token2}\"\n",
    "\n",
    "def synchronize_frames_from_directories(frames_dict, time_multiplier, grid_shape, channel, fps_output=30.0, output_file_path=\"combined_video.avi\"):\n",
    "    \"\"\"\n",
    "    Synchronizes multiple frame directories based on a common time axis.\n",
    "    \n",
    "    Parameters:\n",
    "        frames_dict (dict): Keys are frame directory paths with wildcards (e.g., \"path/to/frames/*.png\"), \n",
    "                           values are frame intervals in seconds.\n",
    "        time_multiplier (float): Multiplier to the base time step.\n",
    "        grid_shape (tuple): (rows, columns) specifying the grid layout.\n",
    "        fps_output (float): Output video playback frames per second.\n",
    "        output_file_path (str): Directory for saving the output video.\n",
    "    \"\"\"\n",
    "    # Convert frames_dict keys and values to lists\n",
    "    frame_patterns = list(frames_dict.keys())\n",
    "    frame_intervals = list(frames_dict.values())\n",
    "    \n",
    "    n_videos = len(frame_patterns)\n",
    "    grid_cells = grid_shape[0] * grid_shape[1]\n",
    "    if grid_cells < n_videos:\n",
    "        raise ValueError(\"Grid shape is too small for the number of videos provided.\")\n",
    "    \n",
    "    # Get actual frame files for each pattern and count them\n",
    "    frame_files_per_video = []\n",
    "    total_frames_list = []\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        # Get all PNG files matching the pattern\n",
    "        frame_files = glob.glob(pattern)\n",
    "        if not frame_files:\n",
    "            raise ValueError(f\"No PNG files found matching pattern: {pattern}\")\n",
    "        \n",
    "        # Sort frames by the actual frame number, not the filename string\n",
    "        def extract_frame_number(filepath):\n",
    "            filename = os.path.basename(filepath)\n",
    "            # Extract number from \"heatmap_frame_55.png\" -> 55\n",
    "            if filename.startswith(\"heatmap_frame_\") and filename.endswith(\".png\"):\n",
    "                number_str = filename[14:-4]  # Remove \"heatmap_frame_\" and \".png\"\n",
    "                try:\n",
    "                    return int(number_str)\n",
    "                except ValueError:\n",
    "                    return 0\n",
    "            return 0\n",
    "        \n",
    "        # Sort by frame number, not by filename string\n",
    "        frame_files = sorted(frame_files, key=extract_frame_number)\n",
    "        \n",
    "        frame_files_per_video.append(frame_files)\n",
    "        total_frames_list.append(len(frame_files))\n",
    "    \n",
    "    # Extract protein names for output naming.\n",
    "    protein_names = [extract_protein_name(fp) for fp in frame_patterns]\n",
    "    proteins_combined = \"-\".join(protein_names)\n",
    "    \n",
    "    # Build the final output file name, including time_multiplier and fps_output.\n",
    "    out_dir = os.path.dirname(output_file_path)\n",
    "    # Format time_multiplier and fps_output for filename (avoid decimal point if possible)\n",
    "    tm_str = f\"{int(time_multiplier)}\" if int(time_multiplier) == time_multiplier else f\"{time_multiplier}\"\n",
    "    fps_str = f\"{int(fps_output)}\" if int(fps_output) == fps_output else f\"{fps_output}\"\n",
    "    final_output_file = os.path.join(\n",
    "        out_dir, \n",
    "        f\"{proteins_combined}_{channel}_synced_tm{tm_str}_fps{fps_str}.avi\"\n",
    "    )\n",
    "    \n",
    "    # Calculate total times and find maximum.\n",
    "    total_times = [frames * interval for frames, interval in zip(total_frames_list, frame_intervals)]\n",
    "    total_time_sync = max(total_times)\n",
    "    \n",
    "    # Compute time step.\n",
    "    base_time_step = min(frame_intervals)\n",
    "    time_step = base_time_step * time_multiplier\n",
    "    \n",
    "    # Determine number of output frames.\n",
    "    num_output_frames = int(total_time_sync / time_step)\n",
    "    \n",
    "    # Calculate playback duration.\n",
    "    playback_duration_sec = num_output_frames / fps_output\n",
    "    print(f\"Movie duration: {playback_duration_sec:.2f} seconds\")\n",
    "    \n",
    "    # Get dimensions from first frame of first directory.\n",
    "    first_frame = cv2.imread(frame_files_per_video[0][0])\n",
    "    if first_frame is None:\n",
    "        raise ValueError(f\"Could not read first frame from {frame_files_per_video[0][0]}\")\n",
    "    \n",
    "    h, w = first_frame.shape[:2]\n",
    "    cell_height, cell_width = h, w\n",
    "    \n",
    "    # Calculate output dimensions.\n",
    "    output_frame_height = grid_shape[0] * cell_height\n",
    "    output_frame_width = grid_shape[1] * cell_width\n",
    "    \n",
    "    # Create video writer.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter(final_output_file, fourcc, fps_output, (output_frame_width, output_frame_height))\n",
    "    \n",
    "    # Process frames: for each time step, compute the corresponding frame from each directory.\n",
    "    for i in tqdm(range(num_output_frames), desc=\"Processing frames\", unit=\"frame\"):\n",
    "        current_time = i * time_step\n",
    "        frames = []\n",
    "        \n",
    "        for idx, (frame_files, frame_interval) in enumerate(zip(frame_files_per_video, frame_intervals)):\n",
    "            # Calculate which frame we need for this time.\n",
    "            frame_idx = int(round(current_time / frame_interval))\n",
    "            \n",
    "            # Ensure frame index is within bounds.\n",
    "            if frame_idx >= total_frames_list[idx]:\n",
    "                frame_idx = total_frames_list[idx] - 1\n",
    "            \n",
    "            # Get the frame file path.\n",
    "            frame_path = frame_files[frame_idx]\n",
    "            \n",
    "            # Read the frame.\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                # If frame doesn't exist, create a black frame.\n",
    "                frame = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            \n",
    "            frame = cv2.resize(frame, (cell_width, cell_height))\n",
    "            frames.append(frame)\n",
    "        \n",
    "        # Fill remaining grid cells with black frames.\n",
    "        while len(frames) < grid_cells:\n",
    "            black = np.zeros((cell_height, cell_width, 3), dtype=np.uint8)\n",
    "            frames.append(black)\n",
    "        \n",
    "        # Combine frames into grid.\n",
    "        grid_rows = []\n",
    "        for r in range(grid_shape[0]):\n",
    "            row_frames = frames[r * grid_shape[1] : (r + 1) * grid_shape[1]]\n",
    "            row_combined = np.hstack(row_frames)\n",
    "            grid_rows.append(row_combined)\n",
    "        combined_frame = np.vstack(grid_rows)\n",
    "        \n",
    "        out.write(combined_frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Output saved to: {final_output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage with your PNG frame directories:\n",
    "frames_data = {\n",
    "\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/microscope/091325-kbio_txtl-strep_noStrep/5ulTMBorEM-2ulkbio1uMdilutedinStreporNA_/output_data/movies/K401-BIO + Strep_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 60,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/microscope/091325-kbio_txtl-strep_noStrep/5ulTMBorEM-2ulkbio1uMdilutedinStreporNA_/output_data/movies/K401-BIO + H2O_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 60,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/101324-k401-titration-rt/2p5TMB-1ulDNA_/output_data/movies/K401_DNA_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 60,\n",
    "    \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/101324-k401-titration-rt/2p5TMB-1ulDNA_/output_data/movies/negative_Rep1_heatmaps_cy5/heatmap_frame_*.png\": 60,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "output_file_path = \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/all/movies/\"\n",
    "\n",
    "# Now you can use much lower time_multiplier since no seeking issues:\n",
    "time_multiplier = 10  # Maximum temporal resolution!\n",
    "grid_shape = (1, 4)\n",
    "\n",
    "synchronize_frames_from_directories(frames_data, time_multiplier, grid_shape, \n",
    "                                   channel=\"cy5\", fps_output=30, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
