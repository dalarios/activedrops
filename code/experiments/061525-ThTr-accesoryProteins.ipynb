{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import relevant libraries\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "sys.path.append('../../py_files/')\n",
    "import quadrop2 as qd\n",
    "\n",
    "qd.set_plotting_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-procesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "base_dir = \"../../../../Thomson Lab Dropbox/David Larios/activedrops/ubuntu/061525-ThTr-accesoryProteins/\"\n",
    "qd.consolidate_images(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "data_path = \"../../../../Thomson Lab Dropbox/David Larios/activedrops/main/061525-ThTr-accesoryProteins/2ulTM-0p2ulThTr-0p6else_/\"\n",
    "\n",
    "calibration_curve_paths = sorted(glob.glob(\"../../../../Thomson Lab Dropbox/David Larios/activedrops/calibration_curve/***ugml.tif\"))\n",
    "\n",
    "\n",
    "conditions_dict = {\n",
    "    \"ThTr\": \"Pos0\", \n",
    "    \"ThTr_T7\": \"Pos1\", \n",
    "    \"ThTr_PRC1\": \"Pos2\", \n",
    "    \"ThTr_HeAl\": \"Pos3\", \n",
    "    \"ThTr_FtsZ\": \"Pos4\", \n",
    "    \"ThTr_T7_ZapA\": \"Pos5\", \n",
    "    \"ThTr_T7_ZapA_FtsA_FtsZ\": \"Pos6\", \n",
    "    \"ThTr_CetZ\": \"Pos7\", \n",
    "    \"ThTr_Tau\": \"Pos8\", \n",
    "    \"ThTr_K401\": \"Pos9\", \n",
    "\n",
    "}\n",
    "\n",
    "# Organize PosX folders into condition folders  \n",
    "qd.organize_conditions(data_path, conditions_dict)\n",
    "\n",
    "# Now run the existing functions to reorganize the tiffs and rename the folders\n",
    "conditions, subconditions = qd.prepare_conditions(data_path)\n",
    "time_interval_list = [60] * len(conditions)  # time intervals in seconds between frames for each condition\n",
    "\n",
    "# subconditions = ['Rep1']\n",
    "print(\"Conditions:\", conditions)\n",
    "print(\"Subconditions:\", subconditions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd.reorgTiffsToOriginal(data_path, conditions, subconditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "qd.fluorescence_heatmap(\n",
    "    data_path, \n",
    "    conditions,    \n",
    "    subconditions, \n",
    "    channel='cy5', \n",
    "    time_interval_list=time_interval_list, \n",
    "    vmax=18, \n",
    "    skip_frames=1, \n",
    "    calibration_curve_paths=calibration_curve_paths, \n",
    "    show_scalebar=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "qd.create_movies(\n",
    "    data_path, \n",
    "    conditions, \n",
    "    subconditions, \n",
    "    channel='cy5',  \n",
    "    frame_rate=120,\n",
    "    skip_frames=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd.create_combined_heatmap_movie_custom_grid(\n",
    "    data_path, \n",
    "    conditions, \n",
    "    subconditions, \n",
    "    channel='cy5', \n",
    "    grid_rows=2, \n",
    "    grid_cols=5, \n",
    "    frame_rate=120,\n",
    "    batch_size=50\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "qd.fluorescence_heatmap(\n",
    "    data_path, \n",
    "    conditions[:], \n",
    "    subconditions, \n",
    "    channel='GFP', \n",
    "    time_interval_list=time_interval_list, \n",
    "    vmax=400, \n",
    "    skip_frames=16, \n",
    "    calibration_curve_paths=calibration_curve_paths, \n",
    "    show_scalebar=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "qd.create_movies(\n",
    "    data_path, \n",
    "    conditions, \n",
    "    subconditions, \n",
    "    channel='GFP', \n",
    "    frame_rate=60,\n",
    "    skip_frames=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd.create_combined_heatmap_movie_custom_grid(\n",
    "    data_path, \n",
    "    conditions, \n",
    "    subconditions, \n",
    "    channel='GFP', \n",
    "    grid_rows=2, \n",
    "    grid_cols=5,       \n",
    "    frame_rate=7.5,\n",
    "    batch_size=50\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qd.delete_temporary_image_directories(data_path, conditions, subconditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluorescence Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# mw_kda_list = [44.95] * len(conditions)\n",
    "droplet_volume_list = [2] * len(conditions)\n",
    "# protein_lengths_list = [401] * len(conditions) # last one is negative\n",
    "\n",
    "qd.quantify_tiffiles(\n",
    "    data_path, \n",
    "    conditions, \n",
    "    subconditions, \n",
    "    calibration_curve_paths, \n",
    "    droplet_volume_list, \n",
    "    time_interval_list, \n",
    "    skip_frames=1,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIV pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[1:2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd.split_tiffs(data_path, conditions, subconditions, channel='cy5', file_interval=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature limits and other parameters\n",
    "v = 2E-7\n",
    "velocity_limits = (0, v)\n",
    "other_limits = (-0.0005, 0.0005)\n",
    "skip_frames = 1 ### CHANGE THIS TO SKIP FRAMES\n",
    "\n",
    "\n",
    "velocity_limits = (None, None)\n",
    "other_limits = (None, None)\n",
    "\n",
    "\n",
    "feature_limits = {\n",
    "    # 'u [m/s]': (-v, v), \n",
    "    # 'v [m/s]': (-v, v), \n",
    "    # 'data type [-]': (None, None),\n",
    "    'velocity magnitude [m/s]': velocity_limits,\n",
    "    'vorticity [1/s]': other_limits,\n",
    "    'divergence [1/s]': other_limits,\n",
    "    # 'dcev [1]': (0, 250),\n",
    "    'shear [1/s]': other_limits,\n",
    "    'strain [1/s]': other_limits,\n",
    "    'vector direction [degrees]': (-180, 180),\n",
    "}\n",
    "\n",
    "\n",
    "# Features for PCA and plotting\n",
    "features_pca = [\n",
    "    \"vorticity [1/s]_mean\",\n",
    "    \"velocity magnitude [um/s]\",\n",
    "    \"distance [m]_mean\",\n",
    "    \"divergence [1/s]_mean\",\n",
    "    \"shear [1/s]_mean\",\n",
    "    \"strain [1/s]_mean\",\n",
    "    \"correlation length [um]\", \n",
    "    \"power [W]_mean\",\n",
    "    \"work [J]\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions[::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval_list = [30*12, 30*18, 30*18, 30*18, 30*18, 30*18, 30*18, 30*18,  ]  # time intervals in seconds between frames for each condition\n",
    "\n",
    "\n",
    "# Process PIV data\n",
    "qd.process_piv_data(\n",
    "    data_path, \n",
    "    conditions,    \n",
    "    subconditions, \n",
    "    feature_limits, \n",
    "    time_interval_list, \n",
    "    min_frame=0, \n",
    "    max_frame=None, \n",
    "    skip_frames=1, \n",
    "    plot_autocorrelation=False, \n",
    "    frame_rate=1, \n",
    "    heatmaps=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot features and PCA\n",
    "qd.plot_PIV_all(\n",
    "    data_path, \n",
    "    conditions[:5:-1],\n",
    "    subconditions, \n",
    "    features_pca, \n",
    "    min_frame=0, \n",
    "    max_frame=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression + PIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data and save it to the \"output_data\" directory\n",
    "qd.combine_averaged_dataframes(data_path, conditions, subconditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd.merge_expression_piv_data(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_column = \"time (h)\"  # Example x-axis column\n",
    "# y_column = \"Protein Concentration_nM\"  # Example y-axis column\n",
    "\n",
    "\n",
    "# x_column = \"Protein Concentration_nM\"  # Example y-axis column\n",
    "# y_column = \"velocity magnitude [m/s]_mean\"  # Example y-axis column\n",
    "\n",
    "# x_column = \"time (h)\"  # Example x-axis column\n",
    "# y_column = \"velocity magnitude [m/s]_mean\"  # Example y-axis column\n",
    "\n",
    "# x_column = \"time (h)\"  # Example x-axis column\n",
    "# y_column = \"power [W]_mean\"  # Example y-axis column\n",
    "\n",
    "# x_column = \"time (h)\"  # Example x-axis column\n",
    "# y_column = \"work [J]_mean\"  # Example y-axis column\n",
    "\n",
    "x_column = \"time (h)\"  # Example x-axis column\n",
    "y_column = \"distance [m]_mean\"  # Example y-axis column\n",
    "\n",
    "\n",
    "qd.plot_expression_piv(\n",
    "    data_path,\n",
    "    conditions,\n",
    "    x_column, \n",
    "    y_column, \n",
    "    sigma_x=0.1, \n",
    "    sigma_y=10, \n",
    "    x_log=False, \n",
    "    y_log=True, \n",
    "    min_frame=0, \n",
    "    max_frame=None, \n",
    "    individual_plots=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of features for PCA\n",
    "features_pca = [\n",
    "    \"vorticity [1/s]_mean\",\n",
    "    \"velocity magnitude [m/s]_mean\",\n",
    "    \"distance [m]_mean\",\n",
    "    \"divergence [1/s]_mean\",\n",
    "    \"shear [1/s]_mean\",\n",
    "    \"strain [1/s]_mean\",\n",
    "    \"correlation length [m]_mean\", \n",
    "    \"power [W]_mean\",\n",
    "    \"work [J]_mean\",\n",
    "    'vector direction [degrees]_mean',\n",
    "    \"Protein Concentration_nM\", \n",
    "    'time (min)'\n",
    "]\n",
    "\n",
    "# Run PCA and save plot (with all conditions and subconditions in the same plot)\n",
    "qd.plot_pca_expression_piv(data_path, conditions=conditions, subconditions=subconditions, features=features_pca, sigma=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "qd.delete_outputs(data_path, conditions, subconditions, output_dirs=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set your directory path\n",
    "base_dir = Path(\"../../../../Thomson Lab Dropbox/David Larios/activedrops/ubuntu/060825-ThTr-MTs_MTsFtsZ_FtsZ_FtsZnoDNA/4ultxtl-1ulDNA250ngulorH2O-0p5uldapibeads-1ulFtsZ_/MTs/Rep1/original/\")\n",
    "files = sorted(base_dir.glob(\"img_*_4x_*.tif\"), key=lambda x: x.stat().st_mtime)\n",
    "\n",
    "# Bundle by timestamp groups of 3 (DAPI, GFP, cy5)\n",
    "timepoint_groups = []\n",
    "\n",
    "# Group files into triplets by order (assuming perfect order: [DAPI, GFP, CY5] × N)\n",
    "if len(files) % 3 != 0:\n",
    "    raise ValueError(f\"Number of files ({len(files)}) is not a multiple of 3. Something's wrong.\")\n",
    "\n",
    "for i in range(0, len(files), 3):\n",
    "    group = files[i:i+3]\n",
    "    timepoint_groups.append(group)\n",
    "\n",
    "if len(timepoint_groups) != 1506:\n",
    "    raise ValueError(f\"Expected 1506 timepoints but found {len(timepoint_groups)}. Check the number of groups.\")\n",
    "\n",
    "# Now rename each triplet\n",
    "for new_index, group in enumerate(timepoint_groups):\n",
    "    for file in group:\n",
    "        match = re.match(r\"img_\\d+_4x_(\\w+).tif\", file.name)\n",
    "        if not match:\n",
    "            print(f\"Skipping: {file.name}\")\n",
    "            continue\n",
    "        channel = match.group(1)\n",
    "        new_name = f\"img_{new_index:07d}_4x_{channel}.tif\"\n",
    "        new_path = file.with_name(new_name)\n",
    "        print(f\"{file.name} → {new_name}\")\n",
    "        file.rename(new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define your renaming dictionary\n",
    "conditions_dict = {\n",
    "    \"MTs\": \"Pos0\", \n",
    "    \"MTs-FtsZ\": \"Pos1\", \n",
    "    \"FtsZ\": \"Pos2\", \n",
    "    \"FtsZ-noDNA\": \"Pos3\", \n",
    "    \"MTs-ZapFtsAT7\": \"Pos4\", \n",
    "    \"MTs-FtsZ-ZapFtsAT7\": \"Pos5\", \n",
    "    \"FtsZ-ZapFtsAT7\": \"Pos6\", \n",
    "    \"FtsZ-noDNA-ZapFtsAT7\": \"Pos7\", \n",
    "}\n",
    "\n",
    "# Path to the parent folder that contains the condition folders\n",
    "base_dir = Path(\"../../../../Thomson Lab Dropbox/David Larios/activedrops/ubuntu/060825-ThTr-MTs_MTsFtsZ_FtsZ_FtsZnoDNA/4ultxtl-1ulDNA250ngulorH2O-0p5uldapibeads-1ulFtsZ_1/\")  # 👈 change this\n",
    "\n",
    "# Rename folders\n",
    "for old_name, new_name in conditions_dict.items():\n",
    "    old_path = base_dir / old_name\n",
    "    new_path = base_dir / new_name\n",
    "\n",
    "    if old_path.exists() and old_path.is_dir():\n",
    "        print(f\"Renaming: {old_name} → {new_name}\")\n",
    "        old_path.rename(new_path)\n",
    "    else:\n",
    "        print(f\"Skipping: {old_path} not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
